# Lecture 11 - Notes  

**January 27, 2016**  


## Difference Equations

_definition_: The __Difference Equation__ is a formula for computing an output sample at time $n$ based on past and present input samples and past output samples in the time domain ([source](https://ccrma.stanford.edu/~jos/fp/Difference_Equation_I.html)). We may write the general, causal, LTI difference equation as follows: 

$$\begin{align}
    a_0 y[n] + a_1 y[n - 1] + ... + a_N y[n - N] = b_0 x[n] &+ b_1 x[n-1] + ... + b_M x[n - M] \newline
\end{align}$$

isolating $y[n]$ (and scaling the coefficients by $\frac{1}{a_0}$),

$$\begin{align}
    y[n] = b_0 x[n] &+ b_1 x[n-1] + ... + b_M x[n - M] \newline
    &- a_1 y[n - 1] - ... - a_N y[n - N] \newline
\end{align}$$

or, more concisely,

$$\begin{align}
    y[n] &= \sum_{i=0}^{M} b_i x[n - i] - \sum_{j=1}^{N} a_j y[n-j]
\end{align}$$

where $x$ is the input signal, $y$ is the output signal and $a_j, b_i, i, j$ are the constant coefficients. Alternatively, another way of writing the Difference Equation is,

$$\begin{align}
    \sum_{i=0}^{M} b_i x[n - i] = \sum_{j=0}^{N} a_j y[n-j]
\end{align}$$

note the change of the bound $j$ to accommodate the inclusion of $y[n]$.

#### Example

Consider,

$$\begin{align}
    y[n] â€“ ay[n-1]=x[n]
\end{align}$$

*What is the impulse response of the system?*

This system is causal, therefore the initial rest condition applies, and

$$\begin{align}
    h[n] = 0 \text{ for } n \lt 0
\end{align}$$

So, if $x[n] = \delta[n]$,


$$\begin{align}
    h[n] &= \delta[n] + a h[n-1] \\\\
    h[0] &= \delta[0] + a h[-1] = 1 \\\\
    h[1] &= \delta[1] + a h[0] = a \\\\
    h[2] &= \delta[2] + a h[1] = a^2 \\\\
    h[3] &= \delta[3] + a h[2] = a^3 \\\\
    &~~\vdots \\\\
    h[n] &= a^n \underbrace{u[n]}_\text{Causal} \\\\
\end{align}$$

*For what ranges of $a$ will the system be stable?*

We note that this absolutely summable for $|a| \lt 1$. This means the system is stable for $|a| \lt 1$.

### Condition of Initial Rest

_definition_: We need addition conditions along with the difference equation. The most common is **initial rest**, where an input $x[n] = 0$ for all $n \lt n_0$ leads to $y[n] = 0$ for all $n \lt n_0$.

### Non-recursive Equations

Given,

$$\begin{align}
    y[n] &= \sum_{i=0}^{M} b_i x[n - i] - \sum_{j=1}^{N} a_j y[n-j]
\end{align}$$

if $N = 0$, then,

$$\begin{align}
    y[n] &= \sum_{i=0}^{M} b_i x[n - i]
\end{align}$$

and,

$$\begin{align}
    h[n] &= \sum_{i=0}^{M} b_i \delta[n - i]
\end{align}$$

## Eigenfunctions

#### Recall

Vector $x$ is an __eigenvector__ for matrix $A$ if,


$$\begin{align}
    Ax = \lambda x 
\end{align}$$

where $\lambda$ is the _eigenvalue_.

### Eigenfunctions

Can we extend the concept of __eigenvectors__ to __eigenfunctions__ of a system?

![](http://pages.jh.edu/~signals/lecture1/image/Image07.gif)

Given a system $x[n]\xrightarrow{T} y[n]$ we can write,


$$\begin{align}
    y[n] = T\left\{ x \left[n\right] \right\} = \lambda x
\end{align}$$

#### Example

Given a _moving average_ system,

$$\begin{align}
    y[n] = \frac{x[n] + x[n-1]}{2}
\end{align}$$

suppose $x[n] = \delta[n]$,

$$\begin{align}
    y[n] &= \frac{\delta[n] + \delta[n-1]}{2} \\\\
    &\neq \lambda x
\end{align}$$

which is not an eigenfunction. Let's try again with $x[n] = e^{j \omega_0 n}$, then,

$$\begin{align}
    y[n] &= \frac{e^{j \omega_0 n} + e^{j \omega_0 (n - 1)}}{2} \\\\
    &= e^{j \omega_0 n} \cdot \frac{1 + e^{-j \omega_0}}{2} \\\\
    &=  \underbrace{\left(\frac{1 + e^{-j \omega_0}}{2}\right)}_\lambda \underbrace{e^{j \omega_0 n}}_x\\\\
    &=  \lambda x\\\\
\end{align}$$

### Why Eigenfunctions?

If the input to an LTI system is represented as a linear combination of complex exponentials, then the output can also be represented as a linear combination of the same complex exponential signals.

### The Eigenfunction Property

_definition_: The **eigenfunction property** states given 

$$
    x[n] = e^{j \omega_0 n} \to y[n] = H \left(e^{j \omega_0} \right) \cdot e^{j \omega_0 n}
$$

if $x[n] = \sum_k \alpha_k e^{j \omega_k n}$, then,

$$\begin{align}
    y[n] = \sum_k \alpha_k H \left(e^{j \omega_k} \right) e^{j \omega_k n}
\end{align}$$
