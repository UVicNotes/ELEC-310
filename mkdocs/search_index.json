{
    "docs": [
        {
            "location": "/", 
            "text": "ELEC 310\n\n\nCoursespaces\n\n\n\n\nInstructor\n: Alexandra Albu\n\n\nOffice\n: EOW 307\n\n\nEmail\n: \naalbu@uvic.ca\n\n\nOffice Hours\n: Wednesdays, 1:30 PM to 3:30 PM\n\n\n\n\nOverview\n\n\nTo provide the student with basic knowledge about digital signal processing and the mathematic methods used within this field.\n\n\nTextbook\n\n\nTitle: Discrete-Time Signal Processing\n\nAuthor: Oppenheim and Schafer\n\nPublisher: Prentice Hall\n\nYear: 2009 \n\n\nAssessment\n\n\n\n\n\n\n\n\nTask\n\n\nWeight\n\n\n\n\n\n\n\n\n\n\nAssignments\n\n\n20%\n\n\n\n\n\n\nLab\n\n\n?\n\n\n\n\n\n\nMidterms\n\n\n40%\n\n\n\n\n\n\nFinal\n\n\n40%", 
            "title": "Home"
        }, 
        {
            "location": "/#elec-310", 
            "text": "", 
            "title": "ELEC 310"
        }, 
        {
            "location": "/#coursespaces", 
            "text": "Instructor : Alexandra Albu  Office : EOW 307  Email :  aalbu@uvic.ca  Office Hours : Wednesdays, 1:30 PM to 3:30 PM", 
            "title": "Coursespaces"
        }, 
        {
            "location": "/#overview", 
            "text": "To provide the student with basic knowledge about digital signal processing and the mathematic methods used within this field.", 
            "title": "Overview"
        }, 
        {
            "location": "/#textbook", 
            "text": "Title: Discrete-Time Signal Processing \nAuthor: Oppenheim and Schafer \nPublisher: Prentice Hall \nYear: 2009", 
            "title": "Textbook"
        }, 
        {
            "location": "/#assessment", 
            "text": "Task  Weight      Assignments  20%    Lab  ?    Midterms  40%    Final  40%", 
            "title": "Assessment"
        }, 
        {
            "location": "/2016-01-05/", 
            "text": "Lecture 1 - Notes\n\n\nJanuary 5, 2016\n  \n\n\nELEC 310\n\n\n\n\nInstructor\n: Alexandra Albu\n\n\nCoursespaces\n\n\n\n\nWhy DSP?\n\n\n\n\nVariety of techniques\n\n\nSoftware implementations don't require physical modification\n\n\nAnalog tuning is not required\n\n\n\n\nSignals\n\n\nSignals are a description of how one parameter changes with another parameter.\n\n\n\n\nVoltage changes over time in an electric circuit\n\n\nBrightness changes with distance in an image\n\n\n\n\nThe pattern of the change conveys information. Signals may not convey information directly and may not be free from disturbances, i.e., the signal to noise ratio.\n\n\nWe need to process signals for:\n\n\n\n\nEnhancing the signal-to-noise ratio\n\n\nSignal storage and compression\n\n\nSig transmission and modulation\n\n\nSignal analysis\n\n\n\n\nIndependent Variables\n\n\nTo carry information the signal must have some variation. We represent this with functions,\n\n\ne.g.\n An image signal ${ R(x,y), G(x,y), B(x,y)}$\n\n\nWe'll be looking at time,\n\n\n\n\nContinuous Time Signal\n: $x(t)$\n\n\nDiscreet Time Signal\n: $x[n]$\n\n\n\n\nNotation\n\n\n\n\n\n\n\n\nContinuous\n\n\nDiscreet\n\n\n\n\n\n\n\n\n\n\n$x_c(t)$\n\n\n$x_d[n]$\n\n\n\n\n\n\n\n\nWe can write,\n\n\n\n\n\n    x_d[n] = x_c(nT)\n\n\n\n\n\nwere $T$ is the sampling period.\n\n\nSystems\n\n\nA system is any process that generates an output an output signal when receiving an input signal.\n\n\nWe'll draw signals with block diagrams and model them using transforms.", 
            "title": "2016 01 05"
        }, 
        {
            "location": "/2016-01-05/#lecture-1-notes", 
            "text": "January 5, 2016", 
            "title": "Lecture 1 - Notes"
        }, 
        {
            "location": "/2016-01-05/#elec-310", 
            "text": "Instructor : Alexandra Albu  Coursespaces", 
            "title": "ELEC 310"
        }, 
        {
            "location": "/2016-01-05/#why-dsp", 
            "text": "Variety of techniques  Software implementations don't require physical modification  Analog tuning is not required", 
            "title": "Why DSP?"
        }, 
        {
            "location": "/2016-01-05/#signals", 
            "text": "Signals are a description of how one parameter changes with another parameter.   Voltage changes over time in an electric circuit  Brightness changes with distance in an image   The pattern of the change conveys information. Signals may not convey information directly and may not be free from disturbances, i.e., the signal to noise ratio.  We need to process signals for:   Enhancing the signal-to-noise ratio  Signal storage and compression  Sig transmission and modulation  Signal analysis   Independent Variables  To carry information the signal must have some variation. We represent this with functions,  e.g.  An image signal ${ R(x,y), G(x,y), B(x,y)}$  We'll be looking at time,   Continuous Time Signal : $x(t)$  Discreet Time Signal : $x[n]$   Notation     Continuous  Discreet      $x_c(t)$  $x_d[n]$     We can write,   \n    x_d[n] = x_c(nT)   were $T$ is the sampling period.", 
            "title": "Signals"
        }, 
        {
            "location": "/2016-01-05/#systems", 
            "text": "A system is any process that generates an output an output signal when receiving an input signal.  We'll draw signals with block diagrams and model them using transforms.", 
            "title": "Systems"
        }, 
        {
            "location": "/2016-01-06/", 
            "text": "Lecture 2 - Notes\n\n\nJanuary 6, 2016\n  \n\n\nSignal Representation\n\n\nA sinusoid using 6 data points.\n\n\n\n\n\n    x(t) = \\sum_{k=1}^{6} A_k \\sin{(\\omega_k t +\\phi_k)}\n\n\n\n\n\n\n\n\n\n\n\n$k$\n\n\n$\\omega_k$\n\n\n$A_k$\n\n\n$\\phi_k$\n\n\n\n\n\n\n\n\n\n\n1\n\n\n1\n\n\n0.2388\n\n\n0.1897\n\n\n\n\n\n\n2\n\n\n2\n\n\n...\n\n\n...\n\n\n\n\n\n\n3\n\n\n$2\\sqrt{3}$\n\n\n...\n\n\n...\n\n\n\n\n\n\n4\n\n\n8\n\n\n...\n\n\n...\n\n\n\n\n\n\n5\n\n\n10\n\n\n...\n\n\n...\n\n\n\n\n\n\n6\n\n\n12\n\n\n...\n\n\n...\n\n\n\n\n\n\n\n\nComplex Numbers\n\n\nLet $z_0$ be a complex number with polar coordinates $(r_0,\\Theta_0)$ and cartesian coordinates $(x_0,y_0)$. Then,\n\n\n\n\n\\begin{align}\n    x_0 &= \\mathbb{Re}\\{z_0\\} = r_0 \\cos{\\Theta_0} \\newline\n    y_0 &= \\mathbb{Im}\\{z_0\\} = r_0 \\sin{\\Theta_0}\n\\end{align}\n\n\n\n\nIf we plot $r_0 = 2$ and $\\Theta_0 = \\frac{\\pi}{4}$,\n\n\nPeriodic Properties of Discreet Time Signals\n\n\nWe can represent a discreet signal as,\n\n\n\n\n\n    x[n] = e^{j \\omega_0 n}\n\n\n and we know that,\n\n\n\n\n\n    e^{j (\\omega_0 + 2\\pi) n} = e^{j \\omega_0 n}\n \n\n\n\n\nBecause the signals are periodic we choose an interval length of $2\\pi$, and either $[ -\\pi, \\pi)$ or $[0,2\\pi)$\n\n\nCondition for Periodicity\n\n\nA signal $x[n]$ is periodic with period $N$ if,\n\n\n\n\n\n    e^{j \\omega_0 n} = e^{j \\omega_0 (m+N)}\n\n\n\n\n\nfor all $m \\in \\mathbb{R}$.\n\n\n\n\n\\begin{align}\n    e^{j \\omega_0 n} = e^{j(\\omega_0n + 2k\\pi)} &= e^{j \\omega_0 (m + N)} \\newline\n    \\omega_0n + 2k\\pi &= \\omega_0(m+N) \\newline\n    2k \\pi &= \\omega_0 n\n\\end{align}\n\n\n\n\nExample\n\n\nDetermine the fundamental period of,\n\n\n\n\n\n    x[n] = 2 \\cos{\\left(\\frac{\\pi}{4}n\\right)} + \\sin{\\left(\\frac{\\pi}{8}n\\right)} - 2 \\cos{\\left( \\frac{\\pi}{2}n + \\frac{\\pi}{6} \\right)}\n\n\n\n\n\nSolution\n\n\n$N$ will be $\\text{lcm}{(N_1,N_2,N_3)}$ where,\n\n\n\n\n\n    x[n] = 2 \\underset{x_1}\\cos{\\left(\\frac{\\pi}{4}n\\right)} + \\underset{x_2}\\sin{\\left(\\frac{\\pi}{8}n\\right)} - 2 \\underset{x_3}\\cos{\\left( \\frac{\\pi}{2}n + \\frac{\\pi}{6} \\right)}\n\n\n\n\n\nSo for $N_1$, since $x[n] = x[n + N_1]$ and $\\omega_0 n = \\omega_0 n + 2k\\pi$\n\n\n\n\n\\begin{align}\n    x_1[n + N_1] &= x_1[n] \\newline\n    2 \\cos{\\left(\\frac{\\pi}{4}\\left(n + N_1\\right)\\right)} &= 2 \\cos{\\left(\\frac{\\pi}{4}n\\right)} \\newline\n    2 \\cos{\\left(\\frac{\\pi}{4}\\left(n + N_1\\right)\\right)} &= 2 \\cos{\\left(\\frac{\\pi}{4}n + 2k\\pi\\right)}  \\newline\n    \\frac{\\pi}{4} (n + N_1) &= \\frac{\\pi}{4}n + 2k\\pi \\newline\n    n + N_1 &= n + 8k \\newline\n    N_1 &= 8k \\newline\n\\end{align}\n\n\n\n\nFor $N_2$,\n\n\n\n\n\\begin{align}\n    x_2[n + N_2] &= x_2[n] \\newline\n\\end{align}\n\n\n\n\nand so on.", 
            "title": "2016 01 06"
        }, 
        {
            "location": "/2016-01-06/#lecture-2-notes", 
            "text": "January 6, 2016", 
            "title": "Lecture 2 - Notes"
        }, 
        {
            "location": "/2016-01-06/#signal-representation", 
            "text": "A sinusoid using 6 data points.   \n    x(t) = \\sum_{k=1}^{6} A_k \\sin{(\\omega_k t +\\phi_k)}      $k$  $\\omega_k$  $A_k$  $\\phi_k$      1  1  0.2388  0.1897    2  2  ...  ...    3  $2\\sqrt{3}$  ...  ...    4  8  ...  ...    5  10  ...  ...    6  12  ...  ...", 
            "title": "Signal Representation"
        }, 
        {
            "location": "/2016-01-06/#complex-numbers", 
            "text": "Let $z_0$ be a complex number with polar coordinates $(r_0,\\Theta_0)$ and cartesian coordinates $(x_0,y_0)$. Then,   \\begin{align}\n    x_0 &= \\mathbb{Re}\\{z_0\\} = r_0 \\cos{\\Theta_0} \\newline\n    y_0 &= \\mathbb{Im}\\{z_0\\} = r_0 \\sin{\\Theta_0}\n\\end{align}   If we plot $r_0 = 2$ and $\\Theta_0 = \\frac{\\pi}{4}$,", 
            "title": "Complex Numbers"
        }, 
        {
            "location": "/2016-01-06/#periodic-properties-of-discreet-time-signals", 
            "text": "We can represent a discreet signal as,   \n    x[n] = e^{j \\omega_0 n} \n and we know that,   \n    e^{j (\\omega_0 + 2\\pi) n} = e^{j \\omega_0 n}\n    Because the signals are periodic we choose an interval length of $2\\pi$, and either $[ -\\pi, \\pi)$ or $[0,2\\pi)$", 
            "title": "Periodic Properties of Discreet Time Signals"
        }, 
        {
            "location": "/2016-01-06/#condition-for-periodicity", 
            "text": "A signal $x[n]$ is periodic with period $N$ if,   \n    e^{j \\omega_0 n} = e^{j \\omega_0 (m+N)}   for all $m \\in \\mathbb{R}$.   \\begin{align}\n    e^{j \\omega_0 n} = e^{j(\\omega_0n + 2k\\pi)} &= e^{j \\omega_0 (m + N)} \\newline\n    \\omega_0n + 2k\\pi &= \\omega_0(m+N) \\newline\n    2k \\pi &= \\omega_0 n\n\\end{align}   Example  Determine the fundamental period of,   \n    x[n] = 2 \\cos{\\left(\\frac{\\pi}{4}n\\right)} + \\sin{\\left(\\frac{\\pi}{8}n\\right)} - 2 \\cos{\\left( \\frac{\\pi}{2}n + \\frac{\\pi}{6} \\right)}   Solution  $N$ will be $\\text{lcm}{(N_1,N_2,N_3)}$ where,   \n    x[n] = 2 \\underset{x_1}\\cos{\\left(\\frac{\\pi}{4}n\\right)} + \\underset{x_2}\\sin{\\left(\\frac{\\pi}{8}n\\right)} - 2 \\underset{x_3}\\cos{\\left( \\frac{\\pi}{2}n + \\frac{\\pi}{6} \\right)}   So for $N_1$, since $x[n] = x[n + N_1]$ and $\\omega_0 n = \\omega_0 n + 2k\\pi$   \\begin{align}\n    x_1[n + N_1] &= x_1[n] \\newline\n    2 \\cos{\\left(\\frac{\\pi}{4}\\left(n + N_1\\right)\\right)} &= 2 \\cos{\\left(\\frac{\\pi}{4}n\\right)} \\newline\n    2 \\cos{\\left(\\frac{\\pi}{4}\\left(n + N_1\\right)\\right)} &= 2 \\cos{\\left(\\frac{\\pi}{4}n + 2k\\pi\\right)}  \\newline\n    \\frac{\\pi}{4} (n + N_1) &= \\frac{\\pi}{4}n + 2k\\pi \\newline\n    n + N_1 &= n + 8k \\newline\n    N_1 &= 8k \\newline\n\\end{align}   For $N_2$,   \\begin{align}\n    x_2[n + N_2] &= x_2[n] \\newline\n\\end{align}   and so on.", 
            "title": "Condition for Periodicity"
        }, 
        {
            "location": "/2016-01-08/", 
            "text": "Lecture 3 - Notes\n\n\nJanuary 8, 2016\n  \n\n\nBasic Discreet Time Signals\n\n\nThe Unit Step\n\n\n\n\n\\begin{align}\n    u[n] &= 1 &~\\text{if}~ n \\ge 0 \\newline\n    &= 0 &~\\text{if}~n \\lt 0\n\\end{align}\n\n\n\n\nThe Unit Impulse\n\n\n\n\n\\begin{align}\n    \\delta[n] &= 1 &~\\text{if}~ n = 0 \\newline\n    &= 0 &~\\text{if}~ n \\neq 0\n\\end{align}\n\n\n\n\nRelationship between Unit Impulse and Step\n\n\n\n\n\n    \\delta[n] = u[n] - u[n-1]\n\n\n\n\n\n\n\n\n    u[n] = \\sum_{m = -\\infty}^{n} \\delta[m]\n\n\n\n\n\nProperties\n\n\nThe \nSampling Property\n allows you to fix $x[n]$ if it is multiplied by the unit impulse function,\n\n\n\n\n\n    x[n]\\delta[n-n_0] = x[n_0]\\delta[n-n_0]\n\n\n\n\n\nCompared to Continuous Time\n\n\nIn discreet time $\\delta[0] = 1$ compared to $\\delta(0) =  \\infty$ in continuous time.\n\n\nExponential Signals\n\n\nA discreet time exponential function is of the form,\n\n\n\n\n\n    x[n] = A\\alpha^n\n\n\n\n\n\nwhere $A,\\alpha \\in \\mathbb{C}$.\n\n\nReal Exponential Signals\n\n\nIf $A,\\alpha \\in \\mathbb{R}$, we call it a \nReal Exponential Signal\n and write it as,\n\n\n\n\n\n    x[n] = Ce^{an}\n\n\n\n\n\nwhere $C,a \\in \\mathbb{R}$.\n\n\nSinusoidal Signals\n\n\nWe can write a \nSinusoidal Signal\n in two ways,\n\n\n\n\n\\begin{align}\n    x[n] &= Ae^{j \\omega_0 n} \\newline\n    &= \\cos{(\\omega_0 n + \\varphi)}\n\\end{align}\n\n\n\n\nwe only consider this signal over a period of $2\\pi$ typically $[-\\pi,\\pi]$\n\n\nEven and Odd Symbols\n\n\nA discreet time signal is \neven\n if,\n\n\n\n\n\n    x[n] = x[-n]\n\n\n\n\n\nfor all $n \\in \\mathbb Z$.\n\n\nA signal is \nodd\n if,\n\n\n\n\n\n    x[-n] = -x[n]\n\n\n\n\n\nAny signal can be broken in an even and odd portion, the sum of which is the signal,\n\n\n\n\n\\begin{align}\n    x_{\\text{even}}[n] = \\frac{x[n] + x[-n]}{2}\n\\end{align}\n\n\n\\begin{align}\n    x_{\\text{odd}}[n] = \\frac{x[n] - x[-n]}{2}\n\\end{align}\n\n\n\n\nand,\n\n\n\n\n\\begin{align}\n    x[n] = x_{\\text{even}}[n] + x_{\\text{odd}}[n]\n\\end{align}\n\n\n\n\nTransformations of Discreet Time Signals\n\n\nWe can do a \ntime shift\n by $n_0$ by,\n\n\n\n\n\\begin{align}\n    x_{\\text{shifted}}[n] = x[n-n_0]\n\\end{align}\n\n\n\n\nWe can \nreverse time\n with,\n\n\n\n\n\\begin{align}\n    x_{\\text{reversed}}[n] = x[-n]\n\\end{align}\n\n\n\n\nWe can \nscale time\n by $a$ with,\n\n\n\n\n\\begin{align}\n    x_{\\text{scaled}}[n] = x[an]\n\\end{align}\n\n\n\n\nCombining Transformations\n\n\nRecommended order,\n\n\n\n\nApply the shift\n\n\nApply the scale\n\n\n\n\nTo \nshift\n then \nscale\n, given $x[n]$, find $y[n] = x[an + b]$. So,\n\n\n\n\nShift\n: $w[n] = x[n + b]$\n\n\nScale\n: $y[n] = w[an] = x[an + b]$\n\n\n\n\ntake note that, $w[an] \\neq x[an + ab]$.", 
            "title": "2016 01 08"
        }, 
        {
            "location": "/2016-01-08/#lecture-3-notes", 
            "text": "January 8, 2016", 
            "title": "Lecture 3 - Notes"
        }, 
        {
            "location": "/2016-01-08/#basic-discreet-time-signals", 
            "text": "The Unit Step   \\begin{align}\n    u[n] &= 1 &~\\text{if}~ n \\ge 0 \\newline\n    &= 0 &~\\text{if}~n \\lt 0\n\\end{align}   The Unit Impulse   \\begin{align}\n    \\delta[n] &= 1 &~\\text{if}~ n = 0 \\newline\n    &= 0 &~\\text{if}~ n \\neq 0\n\\end{align}   Relationship between Unit Impulse and Step   \n    \\delta[n] = u[n] - u[n-1]    \n    u[n] = \\sum_{m = -\\infty}^{n} \\delta[m]   Properties  The  Sampling Property  allows you to fix $x[n]$ if it is multiplied by the unit impulse function,   \n    x[n]\\delta[n-n_0] = x[n_0]\\delta[n-n_0]   Compared to Continuous Time  In discreet time $\\delta[0] = 1$ compared to $\\delta(0) =  \\infty$ in continuous time.", 
            "title": "Basic Discreet Time Signals"
        }, 
        {
            "location": "/2016-01-08/#exponential-signals", 
            "text": "A discreet time exponential function is of the form,   \n    x[n] = A\\alpha^n   where $A,\\alpha \\in \\mathbb{C}$.  Real Exponential Signals  If $A,\\alpha \\in \\mathbb{R}$, we call it a  Real Exponential Signal  and write it as,   \n    x[n] = Ce^{an}   where $C,a \\in \\mathbb{R}$.  Sinusoidal Signals  We can write a  Sinusoidal Signal  in two ways,   \\begin{align}\n    x[n] &= Ae^{j \\omega_0 n} \\newline\n    &= \\cos{(\\omega_0 n + \\varphi)}\n\\end{align}   we only consider this signal over a period of $2\\pi$ typically $[-\\pi,\\pi]$", 
            "title": "Exponential Signals"
        }, 
        {
            "location": "/2016-01-08/#even-and-odd-symbols", 
            "text": "A discreet time signal is  even  if,   \n    x[n] = x[-n]   for all $n \\in \\mathbb Z$.  A signal is  odd  if,   \n    x[-n] = -x[n]   Any signal can be broken in an even and odd portion, the sum of which is the signal,   \\begin{align}\n    x_{\\text{even}}[n] = \\frac{x[n] + x[-n]}{2}\n\\end{align}  \\begin{align}\n    x_{\\text{odd}}[n] = \\frac{x[n] - x[-n]}{2}\n\\end{align}   and,   \\begin{align}\n    x[n] = x_{\\text{even}}[n] + x_{\\text{odd}}[n]\n\\end{align}", 
            "title": "Even and Odd Symbols"
        }, 
        {
            "location": "/2016-01-08/#transformations-of-discreet-time-signals", 
            "text": "We can do a  time shift  by $n_0$ by,   \\begin{align}\n    x_{\\text{shifted}}[n] = x[n-n_0]\n\\end{align}   We can  reverse time  with,   \\begin{align}\n    x_{\\text{reversed}}[n] = x[-n]\n\\end{align}   We can  scale time  by $a$ with,   \\begin{align}\n    x_{\\text{scaled}}[n] = x[an]\n\\end{align}   Combining Transformations  Recommended order,   Apply the shift  Apply the scale   To  shift  then  scale , given $x[n]$, find $y[n] = x[an + b]$. So,   Shift : $w[n] = x[n + b]$  Scale : $y[n] = w[an] = x[an + b]$   take note that, $w[an] \\neq x[an + ab]$.", 
            "title": "Transformations of Discreet Time Signals"
        }, 
        {
            "location": "/2016-01-12/", 
            "text": "Lecture 4 - Notes\n\n\nJanuary 12, 2016\n  \n\n\nEnergy and Power of Signals\n\n\nThe notion of power and energy were initially only applicable to signals produced by physical systems only (i.e. v(t), i(t) across a resistor of resistance R). We create a generalization to allow power and energy to characterize any type of signal.\n\n\nWe calculate the energy of a discreet time signal $x[n]$ over $[n_1,n_2]$ as\n\n\n\n\n\n    E_x = \\sum_{-\\infty}^{\\infty} \\left|x[n]\\right|^2\n\n\n\n\n\nExample\n\n\nFind the energy contained in the signal,\n\n\n\n\n\n    x[n] = \\left(\\frac{1}{2}\\right)^n u[n]\n\n\n\n\n\nSolution\n\n\nSince $x[n]$ contains a unit step function, it will be causal, so\n\n\n\n\n\\begin{align}\n    E_x &= \\sum_{-\\infty}^{\\infty} \\left|x[n]\\right|^2 \\newline\n    &=  \\sum_{-\\infty}^{\\infty} \\left|\\left(\\frac{1}{2}\\right)^n u[n]\\right|^2 \\newline\n    &=  \\sum_{0}^{\\infty} \\left|\\left(\\frac{1}{2}\\right)^n \\right|^2 \\newline\n    &=  \\sum_{0}^{\\infty} \\left(\\frac{1}{4}\\right)^n \\newline\n    &=  \\frac{1}{1 - \\frac{1}{4}} \\newline\n    &=  \\frac{4}{3} \\newline\n\\end{align}\n\n\n\n\nGrowing and Decaying\n\n\nGiven an exponential signal,\n\n\n\n\n\n    x[n] = \\left(\\frac{a}{b} \\right)^n u[n]\n\n\n\n\n\nA growing exponential is where $a \\gt b$ and the energy will non-finite. A decaying exponential is where $a \\lt b$ and will (possibly?) have a finite energy.\n\n\nAverage Power\n\n\nA signal with finite energy is called an \nenergy signal\n. Many Discreet Time signals don't have finite energy. For these signals we consider their \naverage power\n.\n\n\n\n\n\\begin{align}\n    P_x = \\lim_{N \\to \\infty} \\frac{1}{2N} \\sum_{-N}^{N - 1} \\left|x[n]\\right|^2\n\\end{align}\n\n\n\n\nDiscreet Time Systems\n\n\nWe represent a discrete-time system as a transformation that maps an input sequence $x[n]$ into a unique output sequence $y[n]$. We can classify these systems as,\n\n\n\n\nMemoryless systems\n\n\nLinear systems\n \n(examples 2.5, 2.6)\n\n\nTime-invariant\n systems \n(example 2.7, 2.8)\n\n\nCausal systems\n \n(example 2.9)\n\n\nStable systems\n \n(example 2.10)\n\n\n\n\nLinear Systems\n\n\ndefinition\n: A system is \nlinear\n if the principle of\nsuperposition holds. \n\n\nThe Property of Superposition\n\n\nIf we consider two inputs to a system $x_1[n]$ and $x_2[n]$, we get two outputs $y_1[n]$ and $y_2[n]$ such that,\n\n\n\n\n\\begin{align}\n    x_1[n] \\to y_1[n] \\newline\n    x_2[n] \\to y_2[n]\n\\end{align}\n\n\n\n\nnow if we create any \nlinear combination\n of $x_1[n]$ and $x_2[n]$, denoted $x_3[n]$. Where,\n\n\n\n\n\\begin{align}\n    x_3[n] = a_1 x_1[n] + a_2 x_2[n]\n\\end{align}\n\n\n\n\nand $a_1, a_2 \\in \\mathbb R$. Then if $y_3[n]$, the system output for $x_3[n]$, is the same linear combination of $y_1[n]$ and $y_2[n]$, i.e., if\n\n\n\n\n\\begin{align}\n    x_3[n] &\\to y_3[n] \\newline\n    &\\text{and} \\newline\n    y_3[n] &= a_1 y_1[n] + a_2 y_2[n]\n\\end{align}\n\n\n\n\nthe system is linear.\n\n\nTime Invariant Systems\n\n\ndefinition\n: A system is \ntime invariant\n if for any input signal $x[n]$ with output signal $y[n]$, i.e.,\n\n\n\n\n\\begin{align}\n    x[n] \\to y[n]\n\\end{align}\n\n\n\n\nthen for any \ntime shift\n $n_0$ where $n_0 \\in \\mathbb Z$,\n\n\n\n\n\\begin{align}\n    x[n - n_0] \\to y[n - n_0]\n\\end{align}", 
            "title": "2016 01 12"
        }, 
        {
            "location": "/2016-01-12/#lecture-4-notes", 
            "text": "January 12, 2016", 
            "title": "Lecture 4 - Notes"
        }, 
        {
            "location": "/2016-01-12/#energy-and-power-of-signals", 
            "text": "The notion of power and energy were initially only applicable to signals produced by physical systems only (i.e. v(t), i(t) across a resistor of resistance R). We create a generalization to allow power and energy to characterize any type of signal.  We calculate the energy of a discreet time signal $x[n]$ over $[n_1,n_2]$ as   \n    E_x = \\sum_{-\\infty}^{\\infty} \\left|x[n]\\right|^2   Example  Find the energy contained in the signal,   \n    x[n] = \\left(\\frac{1}{2}\\right)^n u[n]   Solution  Since $x[n]$ contains a unit step function, it will be causal, so   \\begin{align}\n    E_x &= \\sum_{-\\infty}^{\\infty} \\left|x[n]\\right|^2 \\newline\n    &=  \\sum_{-\\infty}^{\\infty} \\left|\\left(\\frac{1}{2}\\right)^n u[n]\\right|^2 \\newline\n    &=  \\sum_{0}^{\\infty} \\left|\\left(\\frac{1}{2}\\right)^n \\right|^2 \\newline\n    &=  \\sum_{0}^{\\infty} \\left(\\frac{1}{4}\\right)^n \\newline\n    &=  \\frac{1}{1 - \\frac{1}{4}} \\newline\n    &=  \\frac{4}{3} \\newline\n\\end{align}   Growing and Decaying  Given an exponential signal,   \n    x[n] = \\left(\\frac{a}{b} \\right)^n u[n]   A growing exponential is where $a \\gt b$ and the energy will non-finite. A decaying exponential is where $a \\lt b$ and will (possibly?) have a finite energy.  Average Power  A signal with finite energy is called an  energy signal . Many Discreet Time signals don't have finite energy. For these signals we consider their  average power .   \\begin{align}\n    P_x = \\lim_{N \\to \\infty} \\frac{1}{2N} \\sum_{-N}^{N - 1} \\left|x[n]\\right|^2\n\\end{align}", 
            "title": "Energy and Power of Signals"
        }, 
        {
            "location": "/2016-01-12/#discreet-time-systems", 
            "text": "We represent a discrete-time system as a transformation that maps an input sequence $x[n]$ into a unique output sequence $y[n]$. We can classify these systems as,   Memoryless systems  Linear systems   (examples 2.5, 2.6)  Time-invariant  systems  (example 2.7, 2.8)  Causal systems   (example 2.9)  Stable systems   (example 2.10)   Linear Systems  definition : A system is  linear  if the principle of\nsuperposition holds.   The Property of Superposition  If we consider two inputs to a system $x_1[n]$ and $x_2[n]$, we get two outputs $y_1[n]$ and $y_2[n]$ such that,   \\begin{align}\n    x_1[n] \\to y_1[n] \\newline\n    x_2[n] \\to y_2[n]\n\\end{align}   now if we create any  linear combination  of $x_1[n]$ and $x_2[n]$, denoted $x_3[n]$. Where,   \\begin{align}\n    x_3[n] = a_1 x_1[n] + a_2 x_2[n]\n\\end{align}   and $a_1, a_2 \\in \\mathbb R$. Then if $y_3[n]$, the system output for $x_3[n]$, is the same linear combination of $y_1[n]$ and $y_2[n]$, i.e., if   \\begin{align}\n    x_3[n] &\\to y_3[n] \\newline\n    &\\text{and} \\newline\n    y_3[n] &= a_1 y_1[n] + a_2 y_2[n]\n\\end{align}   the system is linear.  Time Invariant Systems  definition : A system is  time invariant  if for any input signal $x[n]$ with output signal $y[n]$, i.e.,   \\begin{align}\n    x[n] \\to y[n]\n\\end{align}   then for any  time shift  $n_0$ where $n_0 \\in \\mathbb Z$,   \\begin{align}\n    x[n - n_0] \\to y[n - n_0]\n\\end{align}", 
            "title": "Discreet Time Systems"
        }, 
        {
            "location": "/2016-01-13/", 
            "text": "Lecture 5 - Notes\n\n\nJanuary 13, 2016\n  \n\n\nStable Systems\n\n\ndefinition\n: A system is \nBIBO (Bounded Input Bounded Output) Stable\n  if and only if every bounded input produces a bounded output.3\n\n\nIf,\n\n\n\n\n\\begin{align}\n    \\left| x[n] \\right| \\lt B_x \n\\end{align}\n\n\n\n\nand,\n\n\n\n\n\\begin{align}\n    \\left| y[n] \\right| \\lt B_y\n\\end{align}\n\n\n\n\nfor all $n$, and for some $B_x, B_y \\in \\mathbb R$ then the system is \nBIBO Stable\n.\n\n\nCausal Systems\n\n\ndefinition\n: A system is \ncausal\n if its output does not depend on \nfuture\n input.\n\n\nExamples\n\n\nThe system for the \nforward difference\n,\n\n\n\n\n\n    y[n] = x[n+1] - x[n]\n\n\n\n\n\nis \nnot causal\n because it depends on future values of $x[n]$, namely $x[n+1]$. The system for the \nbackward difference\n,\n\n\n\n\n\n    y[n] = x[n] - x[n-1]\n\n\n\n\n\nis \ncausal\n because it only depends on past values of $x[n]$.\n\n\nCausal \nSignals\n\n\ndefinition\n: A signal is \ncausal\n if,\n\n\n\n\n\n    x[n] = 0 ~\\forall~ n \\lt 0\n\n\n\n\n\nTesting System Properties\n\n\nExample\n\n\nDetermine the system given by,\n\n\n\n\n\n    T(x[n]) = \\left(\\cos{\\pi n}\\right)x[n]\n\n\n\n\n\nis,\n\n\n\n\nStable\n\n\nCausal\n\n\nLinear\n\n\nTime-Invariant\n\n\n\n\nSolution\n\n\nWe can reduce the system to,\n\n\n\n\n\\begin{align}\n    y[n] &= \\left(\\cos{\\pi n}\\right)x[n] \\newline\n    &= (-1)^n x[n]\n\\end{align}\n\n\n\n\nStability\n\n\nIf $\\left|x[n]\\right| \\lt B_x$, then since $(-1)^n$ is bounded for all $n$,\n\n\n\n\n\\begin{align}\n    \\left|y[n] \\right| \\lt B_x\n\\end{align}\n\n\n\n\nand the system is \nbounded\n.\n\n\nCausality\n\n\nBy inspections we can see that $y[n]$ does not really on any values other than $x[n]$, therefor it is \ncausal\n.\n\n\nLinearity\n\n\nLet,\n\n\n\n\n\n    x[n] = a_1 x_1[n] + a_2 x_2[n]\n\n\n\n\n\nso,\n\n\n\n\n\\begin{align}\n    y[n] &= (1)^n x[n] \\newline\n    &= (1)^n \\left(a_1 x_1[n] + a_2 x_2[n]\\right) \\newline\n    &= (-1)^n a_1 x_1[n] + (-1)^n a_2 x_2[n] \\newline\n    &= a_1 \\left[(-1)^n x_1[n]\\right] + a_2 \\left[(-1)^n  x_2[n]\\right] \\newline\n    &= a_1 y_1[n] + a_2 y_2[n] \\newline\n\\end{align}\n\n\n\n\nand the system is \nlinear\n.\n\n\nTime-Invariant\n\n\nGiven,\n\n\n\n\n\n    y[n] = (-1)^n x[n]\n\n\n\n\n\nIf we test we can find,\n\n\n\n\n\\begin{align}\n    y[n] &= x[n] \\newline\n    y[n-1] &\\neq x[n-1]\n\\end{align}\n\n\n\n\nso the system is not \ntime-invariant\n.\n\n\nLinear Time-Invariant Systems\n\n\ndefinition\n: A \nLinear Time-Invariant (LTI)\n system is characterized by its \nimpulse response\n $h[n]$, i.e., $y[n] = h[n]$ when $x[n] = \\delta[n]$.\n\n\nExample - Ideal Delay\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = x[n - n_d]\n\\end{align}\n\n\n\n\nwhere $-\\infty \\lt n \\lt \\infty$. So,\n\n\n\n\n\\begin{align}\n    h[n] &= \\delta[n - n_d]\n\\end{align}\n\n\n\n\nExample - Moving Average\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} x[n-k]\n\\end{align}\n\n\n\n\nSo,\n\n\n\n\n\\begin{align}\n    h[n] &= \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} \\delta[n-k] \\newline\n    &= \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} \\delta[n-k] \\newline\n\\end{align}\n\n\n\n\nnote this system is \nnot causal\n.\n\n\nExample - Accumulator\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = \\sum_{k = -\\infty}^{n} x[k]\n\\end{align}\n\n\n\n\nthen,\n\n\n\n\n\\begin{align}\n    h[n] &= \\sum_{k = -\\infty}^{n} \\delta[k] \\newline\n    &= \\sum_{m = 0}^{\\infty} \\delta[n - m] \\newline\n    &= u[n] \\newline\n\\end{align}\n\n\n\n\nExample - Downsampler\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = x[Mn]\n\\end{align}\n\n\n\n\nin this case the system is \nnot time-invariant\n. So we can't compute the unit response.\n\n\nExample - Forward Difference\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = x[n+1] - x[n] \n\\end{align}\n\n\n\n\nthen,\n\n\n\n\n\\begin{align}\n    h[n] = \\delta[n+1] - \\delta[n]\n\\end{align}\n\n\n\n\nExample - Backward Difference\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = x[n] - x[n - 1] \n\\end{align}\n\n\n\n\nthen,\n\n\n\n\n\\begin{align}\n    h[n] = \\delta[n] - \\delta[n - 1]\n\\end{align}\n\n\n\n\nwe can see that the backward difference is simply the forward difference time shifted by 1.", 
            "title": "2016 01 13"
        }, 
        {
            "location": "/2016-01-13/#lecture-5-notes", 
            "text": "January 13, 2016     Stable Systems  definition : A system is  BIBO (Bounded Input Bounded Output) Stable   if and only if every bounded input produces a bounded output.3  If,   \\begin{align}\n    \\left| x[n] \\right| \\lt B_x \n\\end{align}   and,   \\begin{align}\n    \\left| y[n] \\right| \\lt B_y\n\\end{align}   for all $n$, and for some $B_x, B_y \\in \\mathbb R$ then the system is  BIBO Stable .  Causal Systems  definition : A system is  causal  if its output does not depend on  future  input.  Examples  The system for the  forward difference ,   \n    y[n] = x[n+1] - x[n]   is  not causal  because it depends on future values of $x[n]$, namely $x[n+1]$. The system for the  backward difference ,   \n    y[n] = x[n] - x[n-1]   is  causal  because it only depends on past values of $x[n]$.  Causal  Signals  definition : A signal is  causal  if,   \n    x[n] = 0 ~\\forall~ n \\lt 0   Testing System Properties  Example  Determine the system given by,   \n    T(x[n]) = \\left(\\cos{\\pi n}\\right)x[n]   is,   Stable  Causal  Linear  Time-Invariant   Solution  We can reduce the system to,   \\begin{align}\n    y[n] &= \\left(\\cos{\\pi n}\\right)x[n] \\newline\n    &= (-1)^n x[n]\n\\end{align}   Stability  If $\\left|x[n]\\right| \\lt B_x$, then since $(-1)^n$ is bounded for all $n$,   \\begin{align}\n    \\left|y[n] \\right| \\lt B_x\n\\end{align}   and the system is  bounded .  Causality  By inspections we can see that $y[n]$ does not really on any values other than $x[n]$, therefor it is  causal .  Linearity  Let,   \n    x[n] = a_1 x_1[n] + a_2 x_2[n]   so,   \\begin{align}\n    y[n] &= (1)^n x[n] \\newline\n    &= (1)^n \\left(a_1 x_1[n] + a_2 x_2[n]\\right) \\newline\n    &= (-1)^n a_1 x_1[n] + (-1)^n a_2 x_2[n] \\newline\n    &= a_1 \\left[(-1)^n x_1[n]\\right] + a_2 \\left[(-1)^n  x_2[n]\\right] \\newline\n    &= a_1 y_1[n] + a_2 y_2[n] \\newline\n\\end{align}   and the system is  linear .  Time-Invariant  Given,   \n    y[n] = (-1)^n x[n]   If we test we can find,   \\begin{align}\n    y[n] &= x[n] \\newline\n    y[n-1] &\\neq x[n-1]\n\\end{align}   so the system is not  time-invariant .", 
            "title": "Lecture 5 - Notes"
        }, 
        {
            "location": "/2016-01-13/#linear-time-invariant-systems", 
            "text": "definition : A  Linear Time-Invariant (LTI)  system is characterized by its  impulse response  $h[n]$, i.e., $y[n] = h[n]$ when $x[n] = \\delta[n]$.  Example - Ideal Delay  Suppose,   \\begin{align}\n    y[n] = x[n - n_d]\n\\end{align}   where $-\\infty \\lt n \\lt \\infty$. So,   \\begin{align}\n    h[n] &= \\delta[n - n_d]\n\\end{align}   Example - Moving Average  Suppose,   \\begin{align}\n    y[n] = \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} x[n-k]\n\\end{align}   So,   \\begin{align}\n    h[n] &= \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} \\delta[n-k] \\newline\n    &= \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} \\delta[n-k] \\newline\n\\end{align}   note this system is  not causal .  Example - Accumulator  Suppose,   \\begin{align}\n    y[n] = \\sum_{k = -\\infty}^{n} x[k]\n\\end{align}   then,   \\begin{align}\n    h[n] &= \\sum_{k = -\\infty}^{n} \\delta[k] \\newline\n    &= \\sum_{m = 0}^{\\infty} \\delta[n - m] \\newline\n    &= u[n] \\newline\n\\end{align}   Example - Downsampler  Suppose,   \\begin{align}\n    y[n] = x[Mn]\n\\end{align}   in this case the system is  not time-invariant . So we can't compute the unit response.  Example - Forward Difference  Suppose,   \\begin{align}\n    y[n] = x[n+1] - x[n] \n\\end{align}   then,   \\begin{align}\n    h[n] = \\delta[n+1] - \\delta[n]\n\\end{align}   Example - Backward Difference  Suppose,   \\begin{align}\n    y[n] = x[n] - x[n - 1] \n\\end{align}   then,   \\begin{align}\n    h[n] = \\delta[n] - \\delta[n - 1]\n\\end{align}   we can see that the backward difference is simply the forward difference time shifted by 1.", 
            "title": "Linear Time-Invariant Systems"
        }
    ]
}