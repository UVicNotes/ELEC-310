{
    "docs": [
        {
            "location": "/", 
            "text": "ELEC 310\n\n\nCoursespaces\n\n\n\n\nInstructor\n: Alexandra Albu\n\n\nOffice\n: EOW 307\n\n\nEmail\n: \naalbu@uvic.ca\n\n\nOffice Hours\n: Wednesdays, 1:30 PM to 3:30 PM\n\n\n\n\nOverview\n\n\nTo provide the student with basic knowledge about digital signal processing and the mathematic methods used within this field.\n\n\nTextbook\n\n\nTitle: Discrete-Time Signal Processing\n\nAuthor: Oppenheim and Schafer\n\nPublisher: Prentice Hall\n\nYear: 2009 \n\n\nAssessment\n\n\n\n\n\n\n\n\nTask\n\n\nWeight\n\n\n\n\n\n\n\n\n\n\nAssignments\n\n\n20%\n\n\n\n\n\n\nLab\n\n\n?\n\n\n\n\n\n\nMidterms\n\n\n40%\n\n\n\n\n\n\nFinal\n\n\n40%", 
            "title": "Home"
        }, 
        {
            "location": "/#elec-310", 
            "text": "", 
            "title": "ELEC 310"
        }, 
        {
            "location": "/#coursespaces", 
            "text": "Instructor : Alexandra Albu  Office : EOW 307  Email :  aalbu@uvic.ca  Office Hours : Wednesdays, 1:30 PM to 3:30 PM", 
            "title": "Coursespaces"
        }, 
        {
            "location": "/#overview", 
            "text": "To provide the student with basic knowledge about digital signal processing and the mathematic methods used within this field.", 
            "title": "Overview"
        }, 
        {
            "location": "/#textbook", 
            "text": "Title: Discrete-Time Signal Processing \nAuthor: Oppenheim and Schafer \nPublisher: Prentice Hall \nYear: 2009", 
            "title": "Textbook"
        }, 
        {
            "location": "/#assessment", 
            "text": "Task  Weight      Assignments  20%    Lab  ?    Midterms  40%    Final  40%", 
            "title": "Assessment"
        }, 
        {
            "location": "/2016-01-05/", 
            "text": "Lecture 1 - Notes\n\n\nJanuary 5, 2016\n  \n\n\nELEC 310\n\n\n\n\nInstructor\n: Alexandra Albu\n\n\nCoursespaces\n\n\n\n\nWhy DSP?\n\n\n\n\nVariety of techniques\n\n\nSoftware implementations don't require physical modification\n\n\nAnalog tuning is not required\n\n\n\n\nSignals\n\n\nSignals are a description of how one parameter changes with another parameter.\n\n\n\n\nVoltage changes over time in an electric circuit\n\n\nBrightness changes with distance in an image\n\n\n\n\nThe pattern of the change conveys information. Signals may not convey information directly and may not be free from disturbances, i.e., the signal to noise ratio.\n\n\nWe need to process signals for:\n\n\n\n\nEnhancing the signal-to-noise ratio\n\n\nSignal storage and compression\n\n\nSig transmission and modulation\n\n\nSignal analysis\n\n\n\n\nIndependent Variables\n\n\nTo carry information the signal must have some variation. We represent this with functions,\n\n\ne.g.\n An image signal ${ R(x,y), G(x,y), B(x,y)}$\n\n\nWe'll be looking at time,\n\n\n\n\nContinuous Time Signal\n: $x(t)$\n\n\nDiscreet Time Signal\n: $x[n]$\n\n\n\n\nNotation\n\n\n\n\n\n\n\n\nContinuous\n\n\nDiscreet\n\n\n\n\n\n\n\n\n\n\n$x_c(t)$\n\n\n$x_d[n]$\n\n\n\n\n\n\n\n\nWe can write,\n\n\n\n\n\n    x_d[n] = x_c(nT)\n\n\n\n\n\nwere $T$ is the sampling period.\n\n\nSystems\n\n\nA system is any process that generates an output an output signal when receiving an input signal.\n\n\nWe'll draw signals with block diagrams and model them using transforms.", 
            "title": "2016 01 05"
        }, 
        {
            "location": "/2016-01-05/#lecture-1-notes", 
            "text": "January 5, 2016", 
            "title": "Lecture 1 - Notes"
        }, 
        {
            "location": "/2016-01-05/#elec-310", 
            "text": "Instructor : Alexandra Albu  Coursespaces", 
            "title": "ELEC 310"
        }, 
        {
            "location": "/2016-01-05/#why-dsp", 
            "text": "Variety of techniques  Software implementations don't require physical modification  Analog tuning is not required", 
            "title": "Why DSP?"
        }, 
        {
            "location": "/2016-01-05/#signals", 
            "text": "Signals are a description of how one parameter changes with another parameter.   Voltage changes over time in an electric circuit  Brightness changes with distance in an image   The pattern of the change conveys information. Signals may not convey information directly and may not be free from disturbances, i.e., the signal to noise ratio.  We need to process signals for:   Enhancing the signal-to-noise ratio  Signal storage and compression  Sig transmission and modulation  Signal analysis", 
            "title": "Signals"
        }, 
        {
            "location": "/2016-01-05/#independent-variables", 
            "text": "To carry information the signal must have some variation. We represent this with functions,  e.g.  An image signal ${ R(x,y), G(x,y), B(x,y)}$  We'll be looking at time,   Continuous Time Signal : $x(t)$  Discreet Time Signal : $x[n]$", 
            "title": "Independent Variables"
        }, 
        {
            "location": "/2016-01-05/#notation", 
            "text": "Continuous  Discreet      $x_c(t)$  $x_d[n]$     We can write,   \n    x_d[n] = x_c(nT)   were $T$ is the sampling period.", 
            "title": "Notation"
        }, 
        {
            "location": "/2016-01-05/#systems", 
            "text": "A system is any process that generates an output an output signal when receiving an input signal.  We'll draw signals with block diagrams and model them using transforms.", 
            "title": "Systems"
        }, 
        {
            "location": "/2016-01-06/", 
            "text": "Lecture 2 - Notes\n\n\nJanuary 6, 2016\n  \n\n\nSignal Representation\n\n\nA sinusoid using 6 data points.\n\n\n\n\n\n    x(t) = \\sum_{k=1}^{6} A_k \\sin{(\\omega_k t +\\phi_k)}\n\n\n\n\n\n\n\n\n\n\n\n$k$\n\n\n$\\omega_k$\n\n\n$A_k$\n\n\n$\\phi_k$\n\n\n\n\n\n\n\n\n\n\n1\n\n\n1\n\n\n0.2388\n\n\n0.1897\n\n\n\n\n\n\n2\n\n\n2\n\n\n...\n\n\n...\n\n\n\n\n\n\n3\n\n\n$2\\sqrt{3}$\n\n\n...\n\n\n...\n\n\n\n\n\n\n4\n\n\n8\n\n\n...\n\n\n...\n\n\n\n\n\n\n5\n\n\n10\n\n\n...\n\n\n...\n\n\n\n\n\n\n6\n\n\n12\n\n\n...\n\n\n...\n\n\n\n\n\n\n\n\nComplex Numbers\n\n\nLet $z_0$ be a complex number with polar coordinates $(r_0,\\Theta_0)$ and cartesian coordinates $(x_0,y_0)$. Then,\n\n\n\n\n\\begin{align}\n    x_0 &= \\mathbb{Re}\\{z_0\\} = r_0 \\cos{\\Theta_0} \\newline\n    y_0 &= \\mathbb{Im}\\{z_0\\} = r_0 \\sin{\\Theta_0}\n\\end{align}\n\n\n\n\nIf we plot $r_0 = 2$ and $\\Theta_0 = \\frac{\\pi}{4}$,\n\n\nPeriodic Properties of Discreet Time Signals\n\n\nWe can represent a discreet signal as,\n\n\n\n\n\n    x[n] = e^{j \\omega_0 n}\n\n\n and we know that,\n\n\n\n\n\n    e^{j (\\omega_0 + 2\\pi) n} = e^{j \\omega_0 n}\n \n\n\n\n\nBecause the signals are periodic we choose an interval length of $2\\pi$, and either $[ -\\pi, \\pi)$ or $[0,2\\pi)$\n\n\nCondition for Periodicity\n\n\nA signal $x[n]$ is periodic with period $N$ if,\n\n\n\n\n\n    e^{j \\omega_0 n} = e^{j \\omega_0 (m+N)}\n\n\n\n\n\nfor all $m \\in \\mathbb{R}$.\n\n\n\n\n\\begin{align}\n    e^{j \\omega_0 n} = e^{j(\\omega_0n + 2k\\pi)} &= e^{j \\omega_0 (m + N)} \\newline\n    \\omega_0n + 2k\\pi &= \\omega_0(m+N) \\newline\n    2k \\pi &= \\omega_0 n\n\\end{align}\n\n\n\n\nExample\n\n\nDetermine the fundamental period of,\n\n\n\n\n\n    x[n] = 2 \\cos{\\left(\\frac{\\pi}{4}n\\right)} + \\sin{\\left(\\frac{\\pi}{8}n\\right)} - 2 \\cos{\\left( \\frac{\\pi}{2}n + \\frac{\\pi}{6} \\right)}\n\n\n\n\n\nSolution\n\n\n$N$ will be $\\text{lcm}{(N_1,N_2,N_3)}$ where,\n\n\n\n\n\n    x[n] = 2 \\underset{x_1}\\cos{\\left(\\frac{\\pi}{4}n\\right)} + \\underset{x_2}\\sin{\\left(\\frac{\\pi}{8}n\\right)} - 2 \\underset{x_3}\\cos{\\left( \\frac{\\pi}{2}n + \\frac{\\pi}{6} \\right)}\n\n\n\n\n\nSo for $N_1$, since $x[n] = x[n + N_1]$ and $\\omega_0 n = \\omega_0 n + 2k\\pi$\n\n\n\n\n\\begin{align}\n    x_1[n + N_1] &= x_1[n] \\newline\n    2 \\cos{\\left(\\frac{\\pi}{4}\\left(n + N_1\\right)\\right)} &= 2 \\cos{\\left(\\frac{\\pi}{4}n\\right)} \\newline\n    2 \\cos{\\left(\\frac{\\pi}{4}\\left(n + N_1\\right)\\right)} &= 2 \\cos{\\left(\\frac{\\pi}{4}n + 2k\\pi\\right)}  \\newline\n    \\frac{\\pi}{4} (n + N_1) &= \\frac{\\pi}{4}n + 2k\\pi \\newline\n    n + N_1 &= n + 8k \\newline\n    N_1 &= 8k \\newline\n\\end{align}\n\n\n\n\nFor $N_2$,\n\n\n\n\n\\begin{align}\n    x_2[n + N_2] &= x_2[n] \\newline\n\\end{align}\n\n\n\n\nand so on.", 
            "title": "2016 01 06"
        }, 
        {
            "location": "/2016-01-06/#lecture-2-notes", 
            "text": "January 6, 2016", 
            "title": "Lecture 2 - Notes"
        }, 
        {
            "location": "/2016-01-06/#signal-representation", 
            "text": "A sinusoid using 6 data points.   \n    x(t) = \\sum_{k=1}^{6} A_k \\sin{(\\omega_k t +\\phi_k)}      $k$  $\\omega_k$  $A_k$  $\\phi_k$      1  1  0.2388  0.1897    2  2  ...  ...    3  $2\\sqrt{3}$  ...  ...    4  8  ...  ...    5  10  ...  ...    6  12  ...  ...", 
            "title": "Signal Representation"
        }, 
        {
            "location": "/2016-01-06/#complex-numbers", 
            "text": "Let $z_0$ be a complex number with polar coordinates $(r_0,\\Theta_0)$ and cartesian coordinates $(x_0,y_0)$. Then,   \\begin{align}\n    x_0 &= \\mathbb{Re}\\{z_0\\} = r_0 \\cos{\\Theta_0} \\newline\n    y_0 &= \\mathbb{Im}\\{z_0\\} = r_0 \\sin{\\Theta_0}\n\\end{align}   If we plot $r_0 = 2$ and $\\Theta_0 = \\frac{\\pi}{4}$,", 
            "title": "Complex Numbers"
        }, 
        {
            "location": "/2016-01-06/#periodic-properties-of-discreet-time-signals", 
            "text": "We can represent a discreet signal as,   \n    x[n] = e^{j \\omega_0 n} \n and we know that,   \n    e^{j (\\omega_0 + 2\\pi) n} = e^{j \\omega_0 n}\n    Because the signals are periodic we choose an interval length of $2\\pi$, and either $[ -\\pi, \\pi)$ or $[0,2\\pi)$", 
            "title": "Periodic Properties of Discreet Time Signals"
        }, 
        {
            "location": "/2016-01-06/#condition-for-periodicity", 
            "text": "A signal $x[n]$ is periodic with period $N$ if,   \n    e^{j \\omega_0 n} = e^{j \\omega_0 (m+N)}   for all $m \\in \\mathbb{R}$.   \\begin{align}\n    e^{j \\omega_0 n} = e^{j(\\omega_0n + 2k\\pi)} &= e^{j \\omega_0 (m + N)} \\newline\n    \\omega_0n + 2k\\pi &= \\omega_0(m+N) \\newline\n    2k \\pi &= \\omega_0 n\n\\end{align}", 
            "title": "Condition for Periodicity"
        }, 
        {
            "location": "/2016-01-06/#example", 
            "text": "Determine the fundamental period of,   \n    x[n] = 2 \\cos{\\left(\\frac{\\pi}{4}n\\right)} + \\sin{\\left(\\frac{\\pi}{8}n\\right)} - 2 \\cos{\\left( \\frac{\\pi}{2}n + \\frac{\\pi}{6} \\right)}", 
            "title": "Example"
        }, 
        {
            "location": "/2016-01-06/#solution", 
            "text": "$N$ will be $\\text{lcm}{(N_1,N_2,N_3)}$ where,   \n    x[n] = 2 \\underset{x_1}\\cos{\\left(\\frac{\\pi}{4}n\\right)} + \\underset{x_2}\\sin{\\left(\\frac{\\pi}{8}n\\right)} - 2 \\underset{x_3}\\cos{\\left( \\frac{\\pi}{2}n + \\frac{\\pi}{6} \\right)}   So for $N_1$, since $x[n] = x[n + N_1]$ and $\\omega_0 n = \\omega_0 n + 2k\\pi$   \\begin{align}\n    x_1[n + N_1] &= x_1[n] \\newline\n    2 \\cos{\\left(\\frac{\\pi}{4}\\left(n + N_1\\right)\\right)} &= 2 \\cos{\\left(\\frac{\\pi}{4}n\\right)} \\newline\n    2 \\cos{\\left(\\frac{\\pi}{4}\\left(n + N_1\\right)\\right)} &= 2 \\cos{\\left(\\frac{\\pi}{4}n + 2k\\pi\\right)}  \\newline\n    \\frac{\\pi}{4} (n + N_1) &= \\frac{\\pi}{4}n + 2k\\pi \\newline\n    n + N_1 &= n + 8k \\newline\n    N_1 &= 8k \\newline\n\\end{align}   For $N_2$,   \\begin{align}\n    x_2[n + N_2] &= x_2[n] \\newline\n\\end{align}   and so on.", 
            "title": "Solution"
        }, 
        {
            "location": "/2016-01-08/", 
            "text": "Lecture 3 - Notes\n\n\nJanuary 8, 2016\n  \n\n\nBasic Discreet Time Signals\n\n\nThe Unit Step\n\n\n\n\n\\begin{align}\n    u[n] &= 1 &~\\text{if}~ n \\ge 0 \\newline\n    &= 0 &~\\text{if}~n \\lt 0\n\\end{align}\n\n\n\n\nThe Unit Impulse\n\n\n\n\n\\begin{align}\n    \\delta[n] &= 1 &~\\text{if}~ n = 0 \\newline\n    &= 0 &~\\text{if}~ n \\neq 0\n\\end{align}\n\n\n\n\nRelationship between Unit Impulse and Step\n\n\n\n\n\n    \\delta[n] = u[n] - u[n-1]\n\n\n\n\n\n\n\n\n    u[n] = \\sum_{m = -\\infty}^{n} \\delta[m]\n\n\n\n\n\nProperties\n\n\nThe \nSampling Property\n allows you to fix $x[n]$ if it is multiplied by the unit impulse function,\n\n\n\n\n\n    x[n]\\delta[n-n_0] = x[n_0]\\delta[n-n_0]\n\n\n\n\n\nCompared to Continuous Time\n\n\nIn discreet time $\\delta[0] = 1$ compared to $\\delta(0) =  \\infty$ in continuous time.\n\n\nExponential Signals\n\n\nA discreet time exponential function is of the form,\n\n\n\n\n\n    x[n] = A\\alpha^n\n\n\n\n\n\nwhere $A,\\alpha \\in \\mathbb{C}$.\n\n\nReal Exponential Signals\n\n\nIf $A,\\alpha \\in \\mathbb{R}$, we call it a \nReal Exponential Signal\n and write it as,\n\n\n\n\n\n    x[n] = Ce^{an}\n\n\n\n\n\nwhere $C,a \\in \\mathbb{R}$.\n\n\nSinusoidal Signals\n\n\nWe can write a \nSinusoidal Signal\n in two ways,\n\n\n\n\n\\begin{align}\n    x[n] &= Ae^{j \\omega_0 n} \\newline\n    &= \\cos{(\\omega_0 n + \\varphi)}\n\\end{align}\n\n\n\n\nwe only consider this signal over a period of $2\\pi$ typically $[-\\pi,\\pi]$\n\n\nEven and Odd Symbols\n\n\nA discreet time signal is \neven\n if,\n\n\n\n\n\n    x[n] = x[-n]\n\n\n\n\n\nfor all $n \\in \\mathbb Z$.\n\n\nA signal is \nodd\n if,\n\n\n\n\n\n    x[-n] = -x[n]\n\n\n\n\n\nAny signal can be broken in an even and odd portion, the sum of which is the signal,\n\n\n\n\n\\begin{align}\n    x_{\\text{even}}[n] = \\frac{x[n] + x[-n]}{2}\n\\end{align}\n\n\n\\begin{align}\n    x_{\\text{odd}}[n] = \\frac{x[n] - x[-n]}{2}\n\\end{align}\n\n\n\n\nand,\n\n\n\n\n\\begin{align}\n    x[n] = x_{\\text{even}}[n] + x_{\\text{odd}}[n]\n\\end{align}\n\n\n\n\nTransformations of Discreet Time Signals\n\n\nWe can do a \ntime shift\n by $n_0$ by,\n\n\n\n\n\\begin{align}\n    x_{\\text{shifted}}[n] = x[n-n_0]\n\\end{align}\n\n\n\n\nWe can \nreverse time\n with,\n\n\n\n\n\\begin{align}\n    x_{\\text{reversed}}[n] = x[-n]\n\\end{align}\n\n\n\n\nWe can \nscale time\n by $a$ with,\n\n\n\n\n\\begin{align}\n    x_{\\text{scaled}}[n] = x[an]\n\\end{align}\n\n\n\n\nCombining Transformations\n\n\nRecommended order,\n\n\n\n\nApply the shift\n\n\nApply the scale\n\n\n\n\nTo \nshift\n then \nscale\n, given $x[n]$, find $y[n] = x[an + b]$. So,\n\n\n\n\nShift\n: $w[n] = x[n + b]$\n\n\nScale\n: $y[n] = w[an] = x[an + b]$\n\n\n\n\ntake note that, $w[an] \\neq x[an + ab]$.", 
            "title": "2016 01 08"
        }, 
        {
            "location": "/2016-01-08/#lecture-3-notes", 
            "text": "January 8, 2016", 
            "title": "Lecture 3 - Notes"
        }, 
        {
            "location": "/2016-01-08/#basic-discreet-time-signals", 
            "text": "", 
            "title": "Basic Discreet Time Signals"
        }, 
        {
            "location": "/2016-01-08/#the-unit-step", 
            "text": "\\begin{align}\n    u[n] &= 1 &~\\text{if}~ n \\ge 0 \\newline\n    &= 0 &~\\text{if}~n \\lt 0\n\\end{align}", 
            "title": "The Unit Step"
        }, 
        {
            "location": "/2016-01-08/#the-unit-impulse", 
            "text": "\\begin{align}\n    \\delta[n] &= 1 &~\\text{if}~ n = 0 \\newline\n    &= 0 &~\\text{if}~ n \\neq 0\n\\end{align}", 
            "title": "The Unit Impulse"
        }, 
        {
            "location": "/2016-01-08/#relationship-between-unit-impulse-and-step", 
            "text": "\\delta[n] = u[n] - u[n-1]    \n    u[n] = \\sum_{m = -\\infty}^{n} \\delta[m]", 
            "title": "Relationship between Unit Impulse and Step"
        }, 
        {
            "location": "/2016-01-08/#properties", 
            "text": "The  Sampling Property  allows you to fix $x[n]$ if it is multiplied by the unit impulse function,   \n    x[n]\\delta[n-n_0] = x[n_0]\\delta[n-n_0]", 
            "title": "Properties"
        }, 
        {
            "location": "/2016-01-08/#compared-to-continuous-time", 
            "text": "In discreet time $\\delta[0] = 1$ compared to $\\delta(0) =  \\infty$ in continuous time.", 
            "title": "Compared to Continuous Time"
        }, 
        {
            "location": "/2016-01-08/#exponential-signals", 
            "text": "A discreet time exponential function is of the form,   \n    x[n] = A\\alpha^n   where $A,\\alpha \\in \\mathbb{C}$.", 
            "title": "Exponential Signals"
        }, 
        {
            "location": "/2016-01-08/#real-exponential-signals", 
            "text": "If $A,\\alpha \\in \\mathbb{R}$, we call it a  Real Exponential Signal  and write it as,   \n    x[n] = Ce^{an}   where $C,a \\in \\mathbb{R}$.", 
            "title": "Real Exponential Signals"
        }, 
        {
            "location": "/2016-01-08/#sinusoidal-signals", 
            "text": "We can write a  Sinusoidal Signal  in two ways,   \\begin{align}\n    x[n] &= Ae^{j \\omega_0 n} \\newline\n    &= \\cos{(\\omega_0 n + \\varphi)}\n\\end{align}   we only consider this signal over a period of $2\\pi$ typically $[-\\pi,\\pi]$", 
            "title": "Sinusoidal Signals"
        }, 
        {
            "location": "/2016-01-08/#even-and-odd-symbols", 
            "text": "A discreet time signal is  even  if,   \n    x[n] = x[-n]   for all $n \\in \\mathbb Z$.  A signal is  odd  if,   \n    x[-n] = -x[n]   Any signal can be broken in an even and odd portion, the sum of which is the signal,   \\begin{align}\n    x_{\\text{even}}[n] = \\frac{x[n] + x[-n]}{2}\n\\end{align}  \\begin{align}\n    x_{\\text{odd}}[n] = \\frac{x[n] - x[-n]}{2}\n\\end{align}   and,   \\begin{align}\n    x[n] = x_{\\text{even}}[n] + x_{\\text{odd}}[n]\n\\end{align}", 
            "title": "Even and Odd Symbols"
        }, 
        {
            "location": "/2016-01-08/#transformations-of-discreet-time-signals", 
            "text": "We can do a  time shift  by $n_0$ by,   \\begin{align}\n    x_{\\text{shifted}}[n] = x[n-n_0]\n\\end{align}   We can  reverse time  with,   \\begin{align}\n    x_{\\text{reversed}}[n] = x[-n]\n\\end{align}   We can  scale time  by $a$ with,   \\begin{align}\n    x_{\\text{scaled}}[n] = x[an]\n\\end{align}", 
            "title": "Transformations of Discreet Time Signals"
        }, 
        {
            "location": "/2016-01-08/#combining-transformations", 
            "text": "Recommended order,   Apply the shift  Apply the scale   To  shift  then  scale , given $x[n]$, find $y[n] = x[an + b]$. So,   Shift : $w[n] = x[n + b]$  Scale : $y[n] = w[an] = x[an + b]$   take note that, $w[an] \\neq x[an + ab]$.", 
            "title": "Combining Transformations"
        }, 
        {
            "location": "/2016-01-12/", 
            "text": "Lecture 4 - Notes\n\n\nJanuary 12, 2016\n  \n\n\nEnergy and Power of Signals\n\n\nThe notion of power and energy were initially only applicable to signals produced by physical systems only (i.e. v(t), i(t) across a resistor of resistance R). We create a generalization to allow power and energy to characterize any type of signal.\n\n\nWe calculate the energy of a discreet time signal $x[n]$ over $[n_1,n_2]$ as\n\n\n\n\n\n    E_x = \\sum_{-\\infty}^{\\infty} \\left|x[n]\\right|^2\n\n\n\n\n\nExample\n\n\nFind the energy contained in the signal,\n\n\n\n\n\n    x[n] = \\left(\\frac{1}{2}\\right)^n u[n]\n\n\n\n\n\nSolution\n\n\nSince $x[n]$ contains a unit step function, it will be causal, so\n\n\n\n\n\\begin{align}\n    E_x &= \\sum_{-\\infty}^{\\infty} \\left|x[n]\\right|^2 \\newline\n    &=  \\sum_{-\\infty}^{\\infty} \\left|\\left(\\frac{1}{2}\\right)^n u[n]\\right|^2 \\newline\n    &=  \\sum_{0}^{\\infty} \\left|\\left(\\frac{1}{2}\\right)^n \\right|^2 \\newline\n    &=  \\sum_{0}^{\\infty} \\left(\\frac{1}{4}\\right)^n \\newline\n    &=  \\frac{1}{1 - \\frac{1}{4}} \\newline\n    &=  \\frac{4}{3} \\newline\n\\end{align}\n\n\n\n\nGrowing and Decaying\n\n\nGiven an exponential signal,\n\n\n\n\n\n    x[n] = \\left(\\frac{a}{b} \\right)^n u[n]\n\n\n\n\n\nA growing exponential is where $a \\gt b$ and the energy will non-finite. A decaying exponential is where $a \\lt b$ and will (possibly?) have a finite energy.\n\n\nAverage Power\n\n\nA signal with finite energy is called an \nenergy signal\n. Many Discreet Time signals don't have finite energy. For these signals we consider their \naverage power\n.\n\n\n\n\n\\begin{align}\n    P_x = \\lim_{N \\to \\infty} \\frac{1}{2N} \\sum_{-N}^{N - 1} \\left|x[n]\\right|^2\n\\end{align}\n\n\n\n\nDiscreet Time Systems\n\n\nWe represent a discrete-time system as a transformation that maps an input sequence $x[n]$ into a unique output sequence $y[n]$. We can classify these systems as,\n\n\n\n\nMemoryless systems\n\n\nLinear systems\n \n(examples 2.5, 2.6)\n\n\nTime-invariant\n systems \n(example 2.7, 2.8)\n\n\nCausal systems\n \n(example 2.9)\n\n\nStable systems\n \n(example 2.10)\n\n\n\n\nLinear Systems\n\n\ndefinition\n: A system is \nlinear\n if the principle of\nsuperposition holds. \n\n\nThe Property of Superposition\n\n\nIf we consider two inputs to a system $x_1[n]$ and $x_2[n]$, we get two outputs $y_1[n]$ and $y_2[n]$ such that,\n\n\n\n\n\\begin{align}\n    x_1[n] \\to y_1[n] \\newline\n    x_2[n] \\to y_2[n]\n\\end{align}\n\n\n\n\nnow if we create any \nlinear combination\n of $x_1[n]$ and $x_2[n]$, denoted $x_3[n]$. Where,\n\n\n\n\n\\begin{align}\n    x_3[n] = a_1 x_1[n] + a_2 x_2[n]\n\\end{align}\n\n\n\n\nand $a_1, a_2 \\in \\mathbb R$. Then if $y_3[n]$, the system output for $x_3[n]$, is the same linear combination of $y_1[n]$ and $y_2[n]$, i.e., if\n\n\n\n\n\\begin{align}\n    x_3[n] &\\to y_3[n] \\newline\n    &\\text{and} \\newline\n    y_3[n] &= a_1 y_1[n] + a_2 y_2[n]\n\\end{align}\n\n\n\n\nthe system is linear.\n\n\nTime Invariant Systems\n\n\ndefinition\n: A system is \ntime invariant\n if for any input signal $x[n]$ with output signal $y[n]$, i.e.,\n\n\n\n\n\\begin{align}\n    x[n] \\to y[n]\n\\end{align}\n\n\n\n\nthen for any \ntime shift\n $n_0$ where $n_0 \\in \\mathbb Z$,\n\n\n\n\n\\begin{align}\n    x[n - n_0] \\to y[n - n_0]\n\\end{align}", 
            "title": "2016 01 12"
        }, 
        {
            "location": "/2016-01-12/#lecture-4-notes", 
            "text": "January 12, 2016", 
            "title": "Lecture 4 - Notes"
        }, 
        {
            "location": "/2016-01-12/#energy-and-power-of-signals", 
            "text": "The notion of power and energy were initially only applicable to signals produced by physical systems only (i.e. v(t), i(t) across a resistor of resistance R). We create a generalization to allow power and energy to characterize any type of signal.  We calculate the energy of a discreet time signal $x[n]$ over $[n_1,n_2]$ as   \n    E_x = \\sum_{-\\infty}^{\\infty} \\left|x[n]\\right|^2", 
            "title": "Energy and Power of Signals"
        }, 
        {
            "location": "/2016-01-12/#example", 
            "text": "Find the energy contained in the signal,   \n    x[n] = \\left(\\frac{1}{2}\\right)^n u[n]", 
            "title": "Example"
        }, 
        {
            "location": "/2016-01-12/#solution", 
            "text": "Since $x[n]$ contains a unit step function, it will be causal, so   \\begin{align}\n    E_x &= \\sum_{-\\infty}^{\\infty} \\left|x[n]\\right|^2 \\newline\n    &=  \\sum_{-\\infty}^{\\infty} \\left|\\left(\\frac{1}{2}\\right)^n u[n]\\right|^2 \\newline\n    &=  \\sum_{0}^{\\infty} \\left|\\left(\\frac{1}{2}\\right)^n \\right|^2 \\newline\n    &=  \\sum_{0}^{\\infty} \\left(\\frac{1}{4}\\right)^n \\newline\n    &=  \\frac{1}{1 - \\frac{1}{4}} \\newline\n    &=  \\frac{4}{3} \\newline\n\\end{align}", 
            "title": "Solution"
        }, 
        {
            "location": "/2016-01-12/#growing-and-decaying", 
            "text": "Given an exponential signal,   \n    x[n] = \\left(\\frac{a}{b} \\right)^n u[n]   A growing exponential is where $a \\gt b$ and the energy will non-finite. A decaying exponential is where $a \\lt b$ and will (possibly?) have a finite energy.", 
            "title": "Growing and Decaying"
        }, 
        {
            "location": "/2016-01-12/#average-power", 
            "text": "A signal with finite energy is called an  energy signal . Many Discreet Time signals don't have finite energy. For these signals we consider their  average power .   \\begin{align}\n    P_x = \\lim_{N \\to \\infty} \\frac{1}{2N} \\sum_{-N}^{N - 1} \\left|x[n]\\right|^2\n\\end{align}", 
            "title": "Average Power"
        }, 
        {
            "location": "/2016-01-12/#discreet-time-systems", 
            "text": "We represent a discrete-time system as a transformation that maps an input sequence $x[n]$ into a unique output sequence $y[n]$. We can classify these systems as,   Memoryless systems  Linear systems   (examples 2.5, 2.6)  Time-invariant  systems  (example 2.7, 2.8)  Causal systems   (example 2.9)  Stable systems   (example 2.10)", 
            "title": "Discreet Time Systems"
        }, 
        {
            "location": "/2016-01-12/#linear-systems", 
            "text": "definition : A system is  linear  if the principle of\nsuperposition holds.", 
            "title": "Linear Systems"
        }, 
        {
            "location": "/2016-01-12/#the-property-of-superposition", 
            "text": "If we consider two inputs to a system $x_1[n]$ and $x_2[n]$, we get two outputs $y_1[n]$ and $y_2[n]$ such that,   \\begin{align}\n    x_1[n] \\to y_1[n] \\newline\n    x_2[n] \\to y_2[n]\n\\end{align}   now if we create any  linear combination  of $x_1[n]$ and $x_2[n]$, denoted $x_3[n]$. Where,   \\begin{align}\n    x_3[n] = a_1 x_1[n] + a_2 x_2[n]\n\\end{align}   and $a_1, a_2 \\in \\mathbb R$. Then if $y_3[n]$, the system output for $x_3[n]$, is the same linear combination of $y_1[n]$ and $y_2[n]$, i.e., if   \\begin{align}\n    x_3[n] &\\to y_3[n] \\newline\n    &\\text{and} \\newline\n    y_3[n] &= a_1 y_1[n] + a_2 y_2[n]\n\\end{align}   the system is linear.", 
            "title": "The Property of Superposition"
        }, 
        {
            "location": "/2016-01-12/#time-invariant-systems", 
            "text": "definition : A system is  time invariant  if for any input signal $x[n]$ with output signal $y[n]$, i.e.,   \\begin{align}\n    x[n] \\to y[n]\n\\end{align}   then for any  time shift  $n_0$ where $n_0 \\in \\mathbb Z$,   \\begin{align}\n    x[n - n_0] \\to y[n - n_0]\n\\end{align}", 
            "title": "Time Invariant Systems"
        }, 
        {
            "location": "/2016-01-13/", 
            "text": "Lecture 5 - Notes\n\n\nJanuary 13, 2016\n  \n\n\nStable Systems\n\n\ndefinition\n: A system is \nBIBO (Bounded Input Bounded Output) Stable\n  if and only if every bounded input produces a bounded output.3\n\n\nIf,\n\n\n\n\n\\begin{align}\n    \\left| x[n] \\right| \\lt B_x \n\\end{align}\n\n\n\n\nand,\n\n\n\n\n\\begin{align}\n    \\left| y[n] \\right| \\lt B_y\n\\end{align}\n\n\n\n\nfor all $n$, and for some $B_x, B_y \\in \\mathbb R$ then the system is \nBIBO Stable\n.\n\n\nCausal Systems\n\n\ndefinition\n: A system is \ncausal\n if its output does not depend on \nfuture\n input.\n\n\nExamples\n\n\nThe system for the \nforward difference\n,\n\n\n\n\n\n    y[n] = x[n+1] - x[n]\n\n\n\n\n\nis \nnot causal\n because it depends on future values of $x[n]$, namely $x[n+1]$. The system for the \nbackward difference\n,\n\n\n\n\n\n    y[n] = x[n] - x[n-1]\n\n\n\n\n\nis \ncausal\n because it only depends on past values of $x[n]$.\n\n\nCausal \nSignals\n\n\ndefinition\n: A signal is \ncausal\n if,\n\n\n\n\n\n    x[n] = 0 ~\\forall~ n \\lt 0\n\n\n\n\n\nTesting System Properties\n\n\nExample\n\n\nDetermine the system given by,\n\n\n\n\n\n    T(x[n]) = \\left(\\cos{\\pi n}\\right)x[n]\n\n\n\n\n\nis,\n\n\n\n\nStable\n\n\nCausal\n\n\nLinear\n\n\nTime-Invariant\n\n\n\n\nSolution\n\n\nWe can reduce the system to,\n\n\n\n\n\\begin{align}\n    y[n] &= \\left(\\cos{\\pi n}\\right)x[n] \\newline\n    &= (-1)^n x[n]\n\\end{align}\n\n\n\n\nStability\n\n\nIf $\\left|x[n]\\right| \\lt B_x$, then since $(-1)^n$ is bounded for all $n$,\n\n\n\n\n\\begin{align}\n    \\left|y[n] \\right| \\lt B_x\n\\end{align}\n\n\n\n\nand the system is \nbounded\n.\n\n\nCausality\n\n\nBy inspections we can see that $y[n]$ does not really on any values other than $x[n]$, therefor it is \ncausal\n.\n\n\nLinearity\n\n\nLet,\n\n\n\n\n\n    x[n] = a_1 x_1[n] + a_2 x_2[n]\n\n\n\n\n\nso,\n\n\n\n\n\\begin{align}\n    y[n] &= (1)^n x[n] \\newline\n    &= (1)^n \\left(a_1 x_1[n] + a_2 x_2[n]\\right) \\newline\n    &= (-1)^n a_1 x_1[n] + (-1)^n a_2 x_2[n] \\newline\n    &= a_1 \\left[(-1)^n x_1[n]\\right] + a_2 \\left[(-1)^n  x_2[n]\\right] \\newline\n    &= a_1 y_1[n] + a_2 y_2[n] \\newline\n\\end{align}\n\n\n\n\nand the system is \nlinear\n.\n\n\nTime-Invariant\n\n\nGiven,\n\n\n\n\n\n    y[n] = (-1)^n x[n]\n\n\n\n\n\nIf we test we can find,\n\n\n\n\n\\begin{align}\n    y[n] &= x[n] \\newline\n    y[n-1] &\\neq x[n-1]\n\\end{align}\n\n\n\n\nso the system is not \ntime-invariant\n.\n\n\nLinear Time-Invariant Systems\n\n\ndefinition\n: A \nLinear Time-Invariant (LTI)\n system is characterized by its \nimpulse response\n $h[n]$, i.e., $y[n] = h[n]$ when $x[n] = \\delta[n]$.\n\n\nExample - Ideal Delay\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = x[n - n_d]\n\\end{align}\n\n\n\n\nwhere $-\\infty \\lt n \\lt \\infty$. So,\n\n\n\n\n\\begin{align}\n    h[n] &= \\delta[n - n_d]\n\\end{align}\n\n\n\n\nExample - Moving Average\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} x[n-k]\n\\end{align}\n\n\n\n\nSo,\n\n\n\n\n\\begin{align}\n    h[n] &= \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} \\delta[n-k] \\newline\n    &= \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} \\delta[n-k] \\newline\n\\end{align}\n\n\n\n\nnote this system is \nnot causal\n.\n\n\nExample - Accumulator\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = \\sum_{k = -\\infty}^{n} x[k]\n\\end{align}\n\n\n\n\nthen,\n\n\n\n\n\\begin{align}\n    h[n] &= \\sum_{k = -\\infty}^{n} \\delta[k] \\newline\n    &= \\sum_{m = 0}^{\\infty} \\delta[n - m] \\newline\n    &= u[n] \\newline\n\\end{align}\n\n\n\n\nExample - Downsampler\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = x[Mn]\n\\end{align}\n\n\n\n\nin this case the system is \nnot time-invariant\n. So we can't compute the unit response.\n\n\nExample - Forward Difference\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = x[n+1] - x[n] \n\\end{align}\n\n\n\n\nthen,\n\n\n\n\n\\begin{align}\n    h[n] = \\delta[n+1] - \\delta[n]\n\\end{align}\n\n\n\n\nExample - Backward Difference\n\n\nSuppose,\n\n\n\n\n\\begin{align}\n    y[n] = x[n] - x[n - 1] \n\\end{align}\n\n\n\n\nthen,\n\n\n\n\n\\begin{align}\n    h[n] = \\delta[n] - \\delta[n - 1]\n\\end{align}\n\n\n\n\nwe can see that the backward difference is simply the forward difference time shifted by 1.", 
            "title": "2016 01 13"
        }, 
        {
            "location": "/2016-01-13/#lecture-5-notes", 
            "text": "January 13, 2016", 
            "title": "Lecture 5 - Notes"
        }, 
        {
            "location": "/2016-01-13/#stable-systems", 
            "text": "definition : A system is  BIBO (Bounded Input Bounded Output) Stable   if and only if every bounded input produces a bounded output.3  If,   \\begin{align}\n    \\left| x[n] \\right| \\lt B_x \n\\end{align}   and,   \\begin{align}\n    \\left| y[n] \\right| \\lt B_y\n\\end{align}   for all $n$, and for some $B_x, B_y \\in \\mathbb R$ then the system is  BIBO Stable .", 
            "title": "Stable Systems"
        }, 
        {
            "location": "/2016-01-13/#causal-systems", 
            "text": "definition : A system is  causal  if its output does not depend on  future  input.", 
            "title": "Causal Systems"
        }, 
        {
            "location": "/2016-01-13/#examples", 
            "text": "The system for the  forward difference ,   \n    y[n] = x[n+1] - x[n]   is  not causal  because it depends on future values of $x[n]$, namely $x[n+1]$. The system for the  backward difference ,   \n    y[n] = x[n] - x[n-1]   is  causal  because it only depends on past values of $x[n]$.", 
            "title": "Examples"
        }, 
        {
            "location": "/2016-01-13/#causal-signals", 
            "text": "definition : A signal is  causal  if,   \n    x[n] = 0 ~\\forall~ n \\lt 0", 
            "title": "Causal Signals"
        }, 
        {
            "location": "/2016-01-13/#testing-system-properties", 
            "text": "", 
            "title": "Testing System Properties"
        }, 
        {
            "location": "/2016-01-13/#example", 
            "text": "Determine the system given by,   \n    T(x[n]) = \\left(\\cos{\\pi n}\\right)x[n]   is,   Stable  Causal  Linear  Time-Invariant", 
            "title": "Example"
        }, 
        {
            "location": "/2016-01-13/#solution", 
            "text": "We can reduce the system to,   \\begin{align}\n    y[n] &= \\left(\\cos{\\pi n}\\right)x[n] \\newline\n    &= (-1)^n x[n]\n\\end{align}", 
            "title": "Solution"
        }, 
        {
            "location": "/2016-01-13/#stability", 
            "text": "If $\\left|x[n]\\right| \\lt B_x$, then since $(-1)^n$ is bounded for all $n$,   \\begin{align}\n    \\left|y[n] \\right| \\lt B_x\n\\end{align}   and the system is  bounded .", 
            "title": "Stability"
        }, 
        {
            "location": "/2016-01-13/#causality", 
            "text": "By inspections we can see that $y[n]$ does not really on any values other than $x[n]$, therefor it is  causal .", 
            "title": "Causality"
        }, 
        {
            "location": "/2016-01-13/#linearity", 
            "text": "Let,   \n    x[n] = a_1 x_1[n] + a_2 x_2[n]   so,   \\begin{align}\n    y[n] &= (1)^n x[n] \\newline\n    &= (1)^n \\left(a_1 x_1[n] + a_2 x_2[n]\\right) \\newline\n    &= (-1)^n a_1 x_1[n] + (-1)^n a_2 x_2[n] \\newline\n    &= a_1 \\left[(-1)^n x_1[n]\\right] + a_2 \\left[(-1)^n  x_2[n]\\right] \\newline\n    &= a_1 y_1[n] + a_2 y_2[n] \\newline\n\\end{align}   and the system is  linear .", 
            "title": "Linearity"
        }, 
        {
            "location": "/2016-01-13/#time-invariant", 
            "text": "Given,   \n    y[n] = (-1)^n x[n]   If we test we can find,   \\begin{align}\n    y[n] &= x[n] \\newline\n    y[n-1] &\\neq x[n-1]\n\\end{align}   so the system is not  time-invariant .", 
            "title": "Time-Invariant"
        }, 
        {
            "location": "/2016-01-13/#linear-time-invariant-systems", 
            "text": "definition : A  Linear Time-Invariant (LTI)  system is characterized by its  impulse response  $h[n]$, i.e., $y[n] = h[n]$ when $x[n] = \\delta[n]$.", 
            "title": "Linear Time-Invariant Systems"
        }, 
        {
            "location": "/2016-01-13/#example-ideal-delay", 
            "text": "Suppose,   \\begin{align}\n    y[n] = x[n - n_d]\n\\end{align}   where $-\\infty \\lt n \\lt \\infty$. So,   \\begin{align}\n    h[n] &= \\delta[n - n_d]\n\\end{align}", 
            "title": "Example - Ideal Delay"
        }, 
        {
            "location": "/2016-01-13/#example-moving-average", 
            "text": "Suppose,   \\begin{align}\n    y[n] = \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} x[n-k]\n\\end{align}   So,   \\begin{align}\n    h[n] &= \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} \\delta[n-k] \\newline\n    &= \\frac{1}{M_1 + M_2 + 1} \\sum_{k = -M_1}^{M_2} \\delta[n-k] \\newline\n\\end{align}   note this system is  not causal .", 
            "title": "Example - Moving Average"
        }, 
        {
            "location": "/2016-01-13/#example-accumulator", 
            "text": "Suppose,   \\begin{align}\n    y[n] = \\sum_{k = -\\infty}^{n} x[k]\n\\end{align}   then,   \\begin{align}\n    h[n] &= \\sum_{k = -\\infty}^{n} \\delta[k] \\newline\n    &= \\sum_{m = 0}^{\\infty} \\delta[n - m] \\newline\n    &= u[n] \\newline\n\\end{align}", 
            "title": "Example - Accumulator"
        }, 
        {
            "location": "/2016-01-13/#example-downsampler", 
            "text": "Suppose,   \\begin{align}\n    y[n] = x[Mn]\n\\end{align}   in this case the system is  not time-invariant . So we can't compute the unit response.", 
            "title": "Example - Downsampler"
        }, 
        {
            "location": "/2016-01-13/#example-forward-difference", 
            "text": "Suppose,   \\begin{align}\n    y[n] = x[n+1] - x[n] \n\\end{align}   then,   \\begin{align}\n    h[n] = \\delta[n+1] - \\delta[n]\n\\end{align}", 
            "title": "Example - Forward Difference"
        }, 
        {
            "location": "/2016-01-13/#example-backward-difference", 
            "text": "Suppose,   \\begin{align}\n    y[n] = x[n] - x[n - 1] \n\\end{align}   then,   \\begin{align}\n    h[n] = \\delta[n] - \\delta[n - 1]\n\\end{align}   we can see that the backward difference is simply the forward difference time shifted by 1.", 
            "title": "Example - Backward Difference"
        }, 
        {
            "location": "/2016-01-15/", 
            "text": "Lecture 6 - Notes\n\n\nJanuary 15, 2016\n  \n\n\nAdministrative\n\n\nAssignment 1\n\n\n\n\n2.7)\n Complex exponentials are periodic if $\\frac{\\omega_0}{2 \\pi}$ is rational\n\n\n2.28)\n We are asked with limited information about a system\n\n\nb)\n Create a linear combination of the input signals that it is the 0 constant signal, i.e., the input is always 0. Check wether the output is 0 or not.\n\n\nc,d)\n Create linear combinations of the input signals and their time shifted versions.\n\n\n\n\n\n\n\n\nOther\n\n\n\n\nWill be out of class, Dr. Sima will be substituting\n\n\nAssignment 2 will be posted Monday\n\n\n\n\n\n\nLinear Time Invariant Systems --- Continued\n\n\nWhat do we need to know about an LTI system to compute its response to any input signal? In a general way we can represent a discreet signal as,\n\n\n\n\n\\begin{align}\n    x[n] = \\sum_{k = -\\infty}^{\\infty} x[k]\\delta[n-k]\n\\end{align}\n\n\n\n\nWe know that $h[n]$ (the response to $\\delta[n]$), if the system is Linear,\n\n\n\n\n\\begin{align}\n    \\underset{x[n]}{\\sum_{k = -\\infty}^{\\infty} x[k]\\delta[n-k]} \n    \\underset{S}\\longrightarrow\n    \\underset{y[n]}{\\sum_{k = -\\infty}^{\\infty} x[k]h[n-k]}\n\\end{align}\n\n\n\n\nso,\n\n\n\n\n\\begin{align}\n    y[n] = x[n] * h[n]\n\\end{align}\n\n\n\n\nwhere $*$ is the convolution operation.\n\n\nConvolution in Discreet Time\n\n\nFirst Method\n\n\nThe first method is called \nscale, shift, stack and add\n. Given,\n\n\n\n\n\\begin{align}\n    x_1[n] * x_2[n] &= \\sum_{k=-\\infty}^{\\infty} \n    \\underbrace{x_1[n]}_{\\text{Scaling factors}}\n    \\cdot \n    \\underbrace{x_2[n - k]}_{\\text{Time shifted version of } x_2[n]}\n\\end{align}\n\n\n\n\nWe start by sketching $x_1[n]$ and $x_2[n]$, for each discreet signal $p$ in $x_1$ we sum them,\n\n\n\n\n\\begin{align}\n    x_1[n] * x_2[n] = \\sum_{q = 0}^{p} x_1[q]x_2[n - q]\n\\end{align}\n\n\n\n\nSecond Method\n\n\nThis is the \nflip, shift, multiply and add\n method. This is the discreet time version of the continuous time method of convolution. It computes the are of overlap between one signal and the flipped and shifted version of the other signal. Given $x_1[n]$ and $x_2[n]$,\n\n\n\n\nDraw $x_1[k]$ and $x_2[-k]$\n\n\n\n\n\n\n\n\nSlide $x_2[n-k]$  through $x_1[k]$ and calculate the areas\n\n\n\n\n\n\nThird Method\n\n\nThis is the \nanalytical method\n for solving the convolution. Given,\n\n\n\n\n\\begin{align}\n    x_1[n] &= \\left( \\frac{3}{4} \\right)^n u[n] \\newline\n    x_2[n] &= u[n]\n\\end{align}\n\n\n\n\nso,\n\n\n\n\n\\begin{align}\n    x_1[n] * x_2[n] &= \\sum_{k = -\\infty}^{\\infty} x_1[n]x_2[n-k] \\newline\n    &= \\sum_{k = -\\infty}^{\\infty}  \n    \\left( \\frac{3}{4} \\right)^n u[n]\n    u[n-k] \\newline\n\\end{align}\n\n\n\n\nnote that $u[k] = 0$ for all $k \\lt 0$ and $u[n-k] = 0$ for all $0 \\le n \\lt k$, so,\n\n\n\n\n\\begin{align}\n    x_1[n] * x_2[n] &= \\sum_{k = 0}^{n} \\left( \\frac{3}{4} \\right)^n \\newline\n    &= \\frac{\\left( \\frac{3}{4} \\right)\\left(1 - \\left( \\frac{3}{4} \\right)^n \\right)}{1 - \\left( \\frac{3}{4} \\right)} \\newline\n    &= \\frac{\\left( \\frac{3}{4} \\right)\\left(1 - \\left( \\frac{3}{4} \\right)^n \\right)}{\\frac{1}{4}} \\newline\n    &= 3 \\left(1 - \\left( \\frac{3}{4} \\right)^n \\right) \\newline\n    &= \\left\\{\n    \\begin{array}{ll}\n        3 \\left(1 - \\left( \\frac{3}{4} \\right)^n \\right) & \\mbox{if } n \\ge 0 \\newline\n        0 & \\mbox{if } n < 0\n    \\end{array}\n\\right. \\newline\n    &= 3 \\left(1 - \\left( \\frac{3}{4} \\right)^n \\right) u[n] \\newline\n\\end{align}", 
            "title": "2016 01 15"
        }, 
        {
            "location": "/2016-01-15/#lecture-6-notes", 
            "text": "January 15, 2016", 
            "title": "Lecture 6 - Notes"
        }, 
        {
            "location": "/2016-01-15/#administrative", 
            "text": "", 
            "title": "Administrative"
        }, 
        {
            "location": "/2016-01-15/#assignment-1", 
            "text": "2.7)  Complex exponentials are periodic if $\\frac{\\omega_0}{2 \\pi}$ is rational  2.28)  We are asked with limited information about a system  b)  Create a linear combination of the input signals that it is the 0 constant signal, i.e., the input is always 0. Check wether the output is 0 or not.  c,d)  Create linear combinations of the input signals and their time shifted versions.", 
            "title": "Assignment 1"
        }, 
        {
            "location": "/2016-01-15/#other", 
            "text": "Will be out of class, Dr. Sima will be substituting  Assignment 2 will be posted Monday", 
            "title": "Other"
        }, 
        {
            "location": "/2016-01-15/#linear-time-invariant-systems-continued", 
            "text": "What do we need to know about an LTI system to compute its response to any input signal? In a general way we can represent a discreet signal as,   \\begin{align}\n    x[n] = \\sum_{k = -\\infty}^{\\infty} x[k]\\delta[n-k]\n\\end{align}   We know that $h[n]$ (the response to $\\delta[n]$), if the system is Linear,   \\begin{align}\n    \\underset{x[n]}{\\sum_{k = -\\infty}^{\\infty} x[k]\\delta[n-k]} \n    \\underset{S}\\longrightarrow\n    \\underset{y[n]}{\\sum_{k = -\\infty}^{\\infty} x[k]h[n-k]}\n\\end{align}   so,   \\begin{align}\n    y[n] = x[n] * h[n]\n\\end{align}   where $*$ is the convolution operation.", 
            "title": "Linear Time Invariant Systems --- Continued"
        }, 
        {
            "location": "/2016-01-15/#convolution-in-discreet-time", 
            "text": "", 
            "title": "Convolution in Discreet Time"
        }, 
        {
            "location": "/2016-01-15/#first-method", 
            "text": "The first method is called  scale, shift, stack and add . Given,   \\begin{align}\n    x_1[n] * x_2[n] &= \\sum_{k=-\\infty}^{\\infty} \n    \\underbrace{x_1[n]}_{\\text{Scaling factors}}\n    \\cdot \n    \\underbrace{x_2[n - k]}_{\\text{Time shifted version of } x_2[n]}\n\\end{align}   We start by sketching $x_1[n]$ and $x_2[n]$, for each discreet signal $p$ in $x_1$ we sum them,   \\begin{align}\n    x_1[n] * x_2[n] = \\sum_{q = 0}^{p} x_1[q]x_2[n - q]\n\\end{align}", 
            "title": "First Method"
        }, 
        {
            "location": "/2016-01-15/#second-method", 
            "text": "This is the  flip, shift, multiply and add  method. This is the discreet time version of the continuous time method of convolution. It computes the are of overlap between one signal and the flipped and shifted version of the other signal. Given $x_1[n]$ and $x_2[n]$,   Draw $x_1[k]$ and $x_2[-k]$     Slide $x_2[n-k]$  through $x_1[k]$ and calculate the areas", 
            "title": "Second Method"
        }, 
        {
            "location": "/2016-01-15/#third-method", 
            "text": "This is the  analytical method  for solving the convolution. Given,   \\begin{align}\n    x_1[n] &= \\left( \\frac{3}{4} \\right)^n u[n] \\newline\n    x_2[n] &= u[n]\n\\end{align}   so,   \\begin{align}\n    x_1[n] * x_2[n] &= \\sum_{k = -\\infty}^{\\infty} x_1[n]x_2[n-k] \\newline\n    &= \\sum_{k = -\\infty}^{\\infty}  \n    \\left( \\frac{3}{4} \\right)^n u[n]\n    u[n-k] \\newline\n\\end{align}   note that $u[k] = 0$ for all $k \\lt 0$ and $u[n-k] = 0$ for all $0 \\le n \\lt k$, so,   \\begin{align}\n    x_1[n] * x_2[n] &= \\sum_{k = 0}^{n} \\left( \\frac{3}{4} \\right)^n \\newline\n    &= \\frac{\\left( \\frac{3}{4} \\right)\\left(1 - \\left( \\frac{3}{4} \\right)^n \\right)}{1 - \\left( \\frac{3}{4} \\right)} \\newline\n    &= \\frac{\\left( \\frac{3}{4} \\right)\\left(1 - \\left( \\frac{3}{4} \\right)^n \\right)}{\\frac{1}{4}} \\newline\n    &= 3 \\left(1 - \\left( \\frac{3}{4} \\right)^n \\right) \\newline\n    &= \\left\\{\n    \\begin{array}{ll}\n        3 \\left(1 - \\left( \\frac{3}{4} \\right)^n \\right) & \\mbox{if } n \\ge 0 \\newline\n        0 & \\mbox{if } n < 0\n    \\end{array}\n\\right. \\newline\n    &= 3 \\left(1 - \\left( \\frac{3}{4} \\right)^n \\right) u[n] \\newline\n\\end{align}", 
            "title": "Third Method"
        }, 
        {
            "location": "/2016-01-19/", 
            "text": "Lecture 7 - Notes\n\n\nJanuary 19, 2016\n  \n\n\nWays to Describe LTI Systems\n\n\n\n\nThe Impulse Response\n\n\nDifference Equations\n\n\nFrequency Response\n\n\nTransfer Function\n\n\n\n\nDifference Equations\n\n\ndefinition\n: The \nDifference Equation\n is a formula for computing an output sample at time $n$ based on past and present input samples and past output samples in the time domain (\nsource\n). We may write the general, causal, LTI difference equation as follows: \n\n\n\n\n\\begin{align}\n    a_0 y[n] + a_1 y[n - 1] + ... + a_N y[n - N] = b_0 x[n] &+ b_1 x[n-1] + ... + b_M x[n - M] \\newline\n\\end{align}\n\n\n\n\nisolating $y[n]$ (and scaling the coefficients by $\\frac{1}{a_0}$),\n\n\n\n\n\\begin{align}\n    y[n] = b_0 x[n] &+ b_1 x[n-1] + ... + b_M x[n - M] \\newline\n    &- a_1 y[n - 1] - ... - a_N y[n - N] \\newline\n\\end{align}\n\n\n\n\nor, more concisely,\n\n\n\n\n\\begin{align}\n    y[n] &= \\sum_{i=0}^{M} b_i x[n - i] - \\sum_{j=1}^{N} a_j y[n-j]\n\\end{align}\n\n\n\n\nwhere $x$ is the input signal, $y$ is the output signal and $a_j, b_i, i, j$ are the constant coefficients. Alternatively, another way of writing the Difference Equation is,\n\n\n\n\n\\begin{align}\n    \\sum_{i=0}^{M} b_i x[n - i] = \\sum_{j=0}^{N} a_j y[n-j]\n\\end{align}\n\n\n\n\nnote the change of the bound $j$ to accommodate the inclusion of $y[n]$.", 
            "title": "2016 01 19"
        }, 
        {
            "location": "/2016-01-19/#lecture-7-notes", 
            "text": "January 19, 2016", 
            "title": "Lecture 7 - Notes"
        }, 
        {
            "location": "/2016-01-19/#ways-to-describe-lti-systems", 
            "text": "The Impulse Response  Difference Equations  Frequency Response  Transfer Function", 
            "title": "Ways to Describe LTI Systems"
        }, 
        {
            "location": "/2016-01-19/#difference-equations", 
            "text": "definition : The  Difference Equation  is a formula for computing an output sample at time $n$ based on past and present input samples and past output samples in the time domain ( source ). We may write the general, causal, LTI difference equation as follows:    \\begin{align}\n    a_0 y[n] + a_1 y[n - 1] + ... + a_N y[n - N] = b_0 x[n] &+ b_1 x[n-1] + ... + b_M x[n - M] \\newline\n\\end{align}   isolating $y[n]$ (and scaling the coefficients by $\\frac{1}{a_0}$),   \\begin{align}\n    y[n] = b_0 x[n] &+ b_1 x[n-1] + ... + b_M x[n - M] \\newline\n    &- a_1 y[n - 1] - ... - a_N y[n - N] \\newline\n\\end{align}   or, more concisely,   \\begin{align}\n    y[n] &= \\sum_{i=0}^{M} b_i x[n - i] - \\sum_{j=1}^{N} a_j y[n-j]\n\\end{align}   where $x$ is the input signal, $y$ is the output signal and $a_j, b_i, i, j$ are the constant coefficients. Alternatively, another way of writing the Difference Equation is,   \\begin{align}\n    \\sum_{i=0}^{M} b_i x[n - i] = \\sum_{j=0}^{N} a_j y[n-j]\n\\end{align}   note the change of the bound $j$ to accommodate the inclusion of $y[n]$.", 
            "title": "Difference Equations"
        }, 
        {
            "location": "/2016-01-26/", 
            "text": "Lecture 10 - Notes\n\n\nJanuary 26, 2016\n  \n\n\nWe are going over what happened last week again this week.\n\n\nConvolution Properties\n\n\nCommutativity\n\n\n\n\n\n    x * h = h * x\n\n\n\n\n\nAssociativity\n\n\n\n\n\n    x * (y  * h) = (x  * g)  * h\n\n\n\n\n\nDistributivity\n\n\n\n\n\n    x  * (y + h) = (x  * y) + (y  * h)\n\n\n\n\n\nAssociativity with scalar multiplication\n\n\n\n\n\n    a (y  * g) = (a f)  * g\n\n\n\n\n\nLTI Systems from their Unit Impulse\n\n\nCausal\n\n\ndefinition\n: A Linear time invariant system is \ncausal\n if the unit impulse, $h[n]$, is zero for all $n$ greater than zero, i.e.,\n\n\n\n\n\n    h[n] = 0 \\text{ for all } n > 0\n\n\n\n\n\nStability\n\n\ndefinition\n: A Linear time invariant system is \nstable\n if and only if,\n\n\n\n\n\n    \\sum_{n=-\\infty}^{\\infty} \\left| h[n] \\right| \\lt \\infty\n\n\n\n\n\nand $h[n]$ is \nabsolutely summable\n (a finite energy signal).\n\n\nInvertibility\n\n\ndefinition\n: A linear time invariant system is \ninvertible\n if we can find another system that can perfectly reverse the transform of the system. In terms of $h[n]$ the system is invertible if there exist $h^\\prime[n]$ such that,\n\n\n\n\n\n    h[n] * h^\\prime[n] = \\delta[n].", 
            "title": "2016 01 26"
        }, 
        {
            "location": "/2016-01-26/#lecture-10-notes", 
            "text": "January 26, 2016     We are going over what happened last week again this week.", 
            "title": "Lecture 10 - Notes"
        }, 
        {
            "location": "/2016-01-26/#convolution-properties", 
            "text": "", 
            "title": "Convolution Properties"
        }, 
        {
            "location": "/2016-01-26/#commutativity", 
            "text": "x * h = h * x", 
            "title": "Commutativity"
        }, 
        {
            "location": "/2016-01-26/#associativity", 
            "text": "x * (y  * h) = (x  * g)  * h", 
            "title": "Associativity"
        }, 
        {
            "location": "/2016-01-26/#distributivity", 
            "text": "x  * (y + h) = (x  * y) + (y  * h)", 
            "title": "Distributivity"
        }, 
        {
            "location": "/2016-01-26/#associativity-with-scalar-multiplication", 
            "text": "a (y  * g) = (a f)  * g", 
            "title": "Associativity with scalar multiplication"
        }, 
        {
            "location": "/2016-01-26/#lti-systems-from-their-unit-impulse", 
            "text": "", 
            "title": "LTI Systems from their Unit Impulse"
        }, 
        {
            "location": "/2016-01-26/#causal", 
            "text": "definition : A Linear time invariant system is  causal  if the unit impulse, $h[n]$, is zero for all $n$ greater than zero, i.e.,   \n    h[n] = 0 \\text{ for all } n > 0", 
            "title": "Causal"
        }, 
        {
            "location": "/2016-01-26/#stability", 
            "text": "definition : A Linear time invariant system is  stable  if and only if,   \n    \\sum_{n=-\\infty}^{\\infty} \\left| h[n] \\right| \\lt \\infty   and $h[n]$ is  absolutely summable  (a finite energy signal).", 
            "title": "Stability"
        }, 
        {
            "location": "/2016-01-26/#invertibility", 
            "text": "definition : A linear time invariant system is  invertible  if we can find another system that can perfectly reverse the transform of the system. In terms of $h[n]$ the system is invertible if there exist $h^\\prime[n]$ such that,   \n    h[n] * h^\\prime[n] = \\delta[n].", 
            "title": "Invertibility"
        }, 
        {
            "location": "/2016-01-27/", 
            "text": "Lecture 11 - Notes\n\n\nJanuary 27, 2016\n  \n\n\nDifference Equations\n\n\ndefinition\n: The \nDifference Equation\n is a formula for computing an output sample at time $n$ based on past and present input samples and past output samples in the time domain (\nsource\n). We may write the general, causal, LTI difference equation as follows: \n\n\n\n\n\\begin{align}\n    a_0 y[n] + a_1 y[n - 1] + ... + a_N y[n - N] = b_0 x[n] &+ b_1 x[n-1] + ... + b_M x[n - M] \\newline\n\\end{align}\n\n\n\n\nisolating $y[n]$ (and scaling the coefficients by $\\frac{1}{a_0}$),\n\n\n\n\n\\begin{align}\n    y[n] = b_0 x[n] &+ b_1 x[n-1] + ... + b_M x[n - M] \\newline\n    &- a_1 y[n - 1] - ... - a_N y[n - N] \\newline\n\\end{align}\n\n\n\n\nor, more concisely,\n\n\n\n\n\\begin{align}\n    y[n] &= \\sum_{i=0}^{M} b_i x[n - i] - \\sum_{j=1}^{N} a_j y[n-j]\n\\end{align}\n\n\n\n\nwhere $x$ is the input signal, $y$ is the output signal and $a_j, b_i, i, j$ are the constant coefficients. Alternatively, another way of writing the Difference Equation is,\n\n\n\n\n\\begin{align}\n    \\sum_{i=0}^{M} b_i x[n - i] = \\sum_{j=0}^{N} a_j y[n-j]\n\\end{align}\n\n\n\n\nnote the change of the bound $j$ to accommodate the inclusion of $y[n]$.\n\n\nExample\n\n\nConsider,\n\n\n\n\n\\begin{align}\n    y[n] \u2013 ay[n-1]=x[n]\n\\end{align}\n\n\n\n\nWhat is the impulse response of the system?\n\n\nThis system is causal, therefore the initial rest condition applies, and\n\n\n\n\n\\begin{align}\n    h[n] = 0 \\text{ for } n \\lt 0\n\\end{align}\n\n\n\n\nSo, if $x[n] = \\delta[n]$,\n\n\n\n\n\\begin{align}\n    h[n] &= \\delta[n] + a h[n-1] \\\\\\\\\n    h[0] &= \\delta[0] + a h[-1] = 1 \\\\\\\\\n    h[1] &= \\delta[1] + a h[0] = a \\\\\\\\\n    h[2] &= \\delta[2] + a h[1] = a^2 \\\\\\\\\n    h[3] &= \\delta[3] + a h[2] = a^3 \\\\\\\\\n    &~~\\vdots \\\\\\\\\n    h[n] &= a^n \\underbrace{u[n]}_\\text{Causal} \\\\\\\\\n\\end{align}\n\n\n\n\nFor what ranges of $a$ will the system be stable?\n\n\nWe note that this absolutely summable for $|a| \\lt 1$. This means the system is stable for $|a| \\lt 1$.\n\n\nCondition of Initial Rest\n\n\ndefinition\n: We need addition conditions along with the difference equation. The most common is \ninitial rest\n, where an input $x[n] = 0$ for all $n \\lt n_0$ leads to $y[n] = 0$ for all $n \\lt n_0$.\n\n\nNon-recursive Equations\n\n\nGiven,\n\n\n\n\n\\begin{align}\n    y[n] &= \\sum_{i=0}^{M} b_i x[n - i] - \\sum_{j=1}^{N} a_j y[n-j]\n\\end{align}\n\n\n\n\nif $N = 0$, then,\n\n\n\n\n\\begin{align}\n    y[n] &= \\sum_{i=0}^{M} b_i x[n - i]\n\\end{align}\n\n\n\n\nand,\n\n\n\n\n\\begin{align}\n    h[n] &= \\sum_{i=0}^{M} b_i \\delta[n - i]\n\\end{align}\n\n\n\n\nEigenfunctions\n\n\nRecall\n\n\nVector $x$ is an \neigenvector\n for matrix $A$ if,\n\n\n\n\n\\begin{align}\n    Ax = \\lambda x \n\\end{align}\n\n\n\n\nwhere $\\lambda$ is the \neigenvalue\n.\n\n\nEigenfunctions\n\n\nCan we extend the concept of \neigenvectors\n to \neigenfunctions\n of a system?\n\n\n\n\nGiven a system $x[n]\\xrightarrow{T} y[n]$ we can write,\n\n\n\n\n\\begin{align}\n    y[n] = T\\left\\{ x \\left[n\\right] \\right\\} = \\lambda x\n\\end{align}\n\n\n\n\nExample\n\n\nGiven a \nmoving average\n system,\n\n\n\n\n\\begin{align}\n    y[n] = \\frac{x[n] + x[n-1]}{2}\n\\end{align}\n\n\n\n\nsuppose $x[n] = \\delta[n]$,\n\n\n\n\n\\begin{align}\n    y[n] &= \\frac{\\delta[n] + \\delta[n-1]}{2} \\\\\\\\\n    &\\neq \\lambda x\n\\end{align}\n\n\n\n\nwhich is not an eigenfunction. Let's try again with $x[n] = e^{j \\omega_0 n}$, then,\n\n\n\n\n\\begin{align}\n    y[n] &= \\frac{e^{j \\omega_0 n} + e^{j \\omega_0 (n - 1)}}{2} \\\\\\\\\n    &= e^{j \\omega_0 n} \\cdot \\frac{1 + e^{-j \\omega_0}}{2} \\\\\\\\\n    &=  \\underbrace{\\left(\\frac{1 + e^{-j \\omega_0}}{2}\\right)}_\\lambda \\underbrace{e^{j \\omega_0 n}}_x\\\\\\\\\n    &=  \\lambda x\\\\\\\\\n\\end{align}\n\n\n\n\nWhy Eigenfunctions?\n\n\nIf the input to an LTI system is represented as a linear combination of complex exponentials, then the output can also be represented as a linear combination of the same complex exponential signals.\n\n\nThe Eigenfunction Property\n\n\ndefinition\n: The \neigenfunction property\n states given \n\n\n\n\n\n    x[n] = e^{j \\omega_0 n} \\to y[n] = H \\left(e^{j \\omega_0} \\right) \\cdot e^{j \\omega_0 n}\n\n\n\n\n\nif $x[n] = \\sum_k \\alpha_k e^{j \\omega_k n}$, then,\n\n\n\n\n\\begin{align}\n    y[n] = \\sum_k \\alpha_k H \\left(e^{j \\omega_k} \\right) e^{j \\omega_k n}\n\\end{align}", 
            "title": "2016 01 27"
        }, 
        {
            "location": "/2016-01-27/#lecture-11-notes", 
            "text": "January 27, 2016", 
            "title": "Lecture 11 - Notes"
        }, 
        {
            "location": "/2016-01-27/#difference-equations", 
            "text": "definition : The  Difference Equation  is a formula for computing an output sample at time $n$ based on past and present input samples and past output samples in the time domain ( source ). We may write the general, causal, LTI difference equation as follows:    \\begin{align}\n    a_0 y[n] + a_1 y[n - 1] + ... + a_N y[n - N] = b_0 x[n] &+ b_1 x[n-1] + ... + b_M x[n - M] \\newline\n\\end{align}   isolating $y[n]$ (and scaling the coefficients by $\\frac{1}{a_0}$),   \\begin{align}\n    y[n] = b_0 x[n] &+ b_1 x[n-1] + ... + b_M x[n - M] \\newline\n    &- a_1 y[n - 1] - ... - a_N y[n - N] \\newline\n\\end{align}   or, more concisely,   \\begin{align}\n    y[n] &= \\sum_{i=0}^{M} b_i x[n - i] - \\sum_{j=1}^{N} a_j y[n-j]\n\\end{align}   where $x$ is the input signal, $y$ is the output signal and $a_j, b_i, i, j$ are the constant coefficients. Alternatively, another way of writing the Difference Equation is,   \\begin{align}\n    \\sum_{i=0}^{M} b_i x[n - i] = \\sum_{j=0}^{N} a_j y[n-j]\n\\end{align}   note the change of the bound $j$ to accommodate the inclusion of $y[n]$.", 
            "title": "Difference Equations"
        }, 
        {
            "location": "/2016-01-27/#example", 
            "text": "Consider,   \\begin{align}\n    y[n] \u2013 ay[n-1]=x[n]\n\\end{align}   What is the impulse response of the system?  This system is causal, therefore the initial rest condition applies, and   \\begin{align}\n    h[n] = 0 \\text{ for } n \\lt 0\n\\end{align}   So, if $x[n] = \\delta[n]$,   \\begin{align}\n    h[n] &= \\delta[n] + a h[n-1] \\\\\\\\\n    h[0] &= \\delta[0] + a h[-1] = 1 \\\\\\\\\n    h[1] &= \\delta[1] + a h[0] = a \\\\\\\\\n    h[2] &= \\delta[2] + a h[1] = a^2 \\\\\\\\\n    h[3] &= \\delta[3] + a h[2] = a^3 \\\\\\\\\n    &~~\\vdots \\\\\\\\\n    h[n] &= a^n \\underbrace{u[n]}_\\text{Causal} \\\\\\\\\n\\end{align}   For what ranges of $a$ will the system be stable?  We note that this absolutely summable for $|a| \\lt 1$. This means the system is stable for $|a| \\lt 1$.", 
            "title": "Example"
        }, 
        {
            "location": "/2016-01-27/#condition-of-initial-rest", 
            "text": "definition : We need addition conditions along with the difference equation. The most common is  initial rest , where an input $x[n] = 0$ for all $n \\lt n_0$ leads to $y[n] = 0$ for all $n \\lt n_0$.", 
            "title": "Condition of Initial Rest"
        }, 
        {
            "location": "/2016-01-27/#non-recursive-equations", 
            "text": "Given,   \\begin{align}\n    y[n] &= \\sum_{i=0}^{M} b_i x[n - i] - \\sum_{j=1}^{N} a_j y[n-j]\n\\end{align}   if $N = 0$, then,   \\begin{align}\n    y[n] &= \\sum_{i=0}^{M} b_i x[n - i]\n\\end{align}   and,   \\begin{align}\n    h[n] &= \\sum_{i=0}^{M} b_i \\delta[n - i]\n\\end{align}", 
            "title": "Non-recursive Equations"
        }, 
        {
            "location": "/2016-01-27/#eigenfunctions", 
            "text": "", 
            "title": "Eigenfunctions"
        }, 
        {
            "location": "/2016-01-27/#recall", 
            "text": "Vector $x$ is an  eigenvector  for matrix $A$ if,   \\begin{align}\n    Ax = \\lambda x \n\\end{align}   where $\\lambda$ is the  eigenvalue .", 
            "title": "Recall"
        }, 
        {
            "location": "/2016-01-27/#eigenfunctions_1", 
            "text": "Can we extend the concept of  eigenvectors  to  eigenfunctions  of a system?   Given a system $x[n]\\xrightarrow{T} y[n]$ we can write,   \\begin{align}\n    y[n] = T\\left\\{ x \\left[n\\right] \\right\\} = \\lambda x\n\\end{align}", 
            "title": "Eigenfunctions"
        }, 
        {
            "location": "/2016-01-27/#example_1", 
            "text": "Given a  moving average  system,   \\begin{align}\n    y[n] = \\frac{x[n] + x[n-1]}{2}\n\\end{align}   suppose $x[n] = \\delta[n]$,   \\begin{align}\n    y[n] &= \\frac{\\delta[n] + \\delta[n-1]}{2} \\\\\\\\\n    &\\neq \\lambda x\n\\end{align}   which is not an eigenfunction. Let's try again with $x[n] = e^{j \\omega_0 n}$, then,   \\begin{align}\n    y[n] &= \\frac{e^{j \\omega_0 n} + e^{j \\omega_0 (n - 1)}}{2} \\\\\\\\\n    &= e^{j \\omega_0 n} \\cdot \\frac{1 + e^{-j \\omega_0}}{2} \\\\\\\\\n    &=  \\underbrace{\\left(\\frac{1 + e^{-j \\omega_0}}{2}\\right)}_\\lambda \\underbrace{e^{j \\omega_0 n}}_x\\\\\\\\\n    &=  \\lambda x\\\\\\\\\n\\end{align}", 
            "title": "Example"
        }, 
        {
            "location": "/2016-01-27/#why-eigenfunctions", 
            "text": "If the input to an LTI system is represented as a linear combination of complex exponentials, then the output can also be represented as a linear combination of the same complex exponential signals.", 
            "title": "Why Eigenfunctions?"
        }, 
        {
            "location": "/2016-01-27/#the-eigenfunction-property", 
            "text": "definition : The  eigenfunction property  states given    \n    x[n] = e^{j \\omega_0 n} \\to y[n] = H \\left(e^{j \\omega_0} \\right) \\cdot e^{j \\omega_0 n}   if $x[n] = \\sum_k \\alpha_k e^{j \\omega_k n}$, then,   \\begin{align}\n    y[n] = \\sum_k \\alpha_k H \\left(e^{j \\omega_k} \\right) e^{j \\omega_k n}\n\\end{align}", 
            "title": "The Eigenfunction Property"
        }, 
        {
            "location": "/2016-01-29/", 
            "text": "Lecture 12 - Notes\n\n\nJanuary 29, 2016\n  \n\n\nEigenfunctions - Continued\n\n\ndefinition\n: Given a system $y[n] = H\\left(e^{j \\omega}\\right) e^{j \\omega n}$ with an impulse response $h[n]$, the \nfrequency response\n is,\n\n\n\n\n\\begin{align}\n    H\\left(e^{j \\omega}\\right) = \\sum_{n = -\\infty}^{\\infty} h[n] e^{-j \\omega n}\n\\end{align}\n\n\n\n\nGiven a difference equation,\n\n\n\n\n\\begin{align}\n    \\sum_{i=0}^{M} b_i x[n - i] = \\sum_{j=0}^{N} a_j y[n-j]\n\\end{align}\n\n\n\n\nthe frequency response is,\n\n\n\n\n\\begin{align}\n    H\\left(e^{j \\omega}\\right) = \\frac{\\sum_{i=0}^{M} b_i e^{-j \\omega i}}{\\sum_{k=0}^{N} a_k e^{-j \\omega k}}\n\\end{align}\n\n\n\n\nExamples\n\n\nIs $3^n$ an eigenfunction?\n\n\nYes. Since $3^n = \\left(3e^{j0}\\right)^n$.\n\n\nIs $\\cos{\\omega_0 n}$ an eigenfunction?\n\n\nNo.\n\n\nSinusoidal System Responses\n\n\nSuppose, $x[n] = A \\cos{\\omega_0 n + \\varphi}$, then\n\n\n\n\n\\begin{align}\n    x[n] &= A \\cos{\\omega_0 n + \\varphi} \\\\\\\\\n    &= \\frac{A}{2}\\left( e^{j(\\omega_0 n + \\varphi)} + e^{-j(\\omega_0 n + \\varphi)} \\right) \\\\\\\\\n    &= \\frac{A}{2}\\left( e^{j\\omega_0 n}e^{j\\varphi} + e^{-j\\omega_0 n}e^{j\\varphi} \\right) \\\\\\\\\n    &= \\frac{A}{2} e^{j\\omega_0 n}e^{j\\varphi} + \\frac{A}{2} e^{j\\omega_0 n}e^{-j\\varphi} \\\\\\\\\n    &\\xrightarrow{S} \\frac{A}{2} e^{j\\varphi} H\\left(e^{j \\omega_0}\\right) e^{j\\omega_0 n} + \\frac{A}{2} e^{-j\\varphi} H\\left(e^{-j \\omega_0}\\right) e^{j\\omega_0 n}  \\\\\\\\\n\\end{align}\n\n\n\n\nThis gives us,\n\n\n\n\n\\begin{align}\n    y[n] &= \\frac{A}{2} e^{j\\varphi} H\\left(e^{j \\omega_0}\\right) e^{j\\omega_0 n} + \\frac{A}{2} e^{-j\\varphi} H\\left(e^{-j \\omega_0}\\right) e^{j\\omega_0 n} \\\\\\\\\n    &= A \\left|H\\left( e^{j \\omega_0} \\right)\\right|\\cos{\\left(\\omega_0 n + \\varphi - \\theta_0\\right)}\n\\end{align}", 
            "title": "2016 01 29"
        }, 
        {
            "location": "/2016-01-29/#lecture-12-notes", 
            "text": "January 29, 2016", 
            "title": "Lecture 12 - Notes"
        }, 
        {
            "location": "/2016-01-29/#eigenfunctions-continued", 
            "text": "definition : Given a system $y[n] = H\\left(e^{j \\omega}\\right) e^{j \\omega n}$ with an impulse response $h[n]$, the  frequency response  is,   \\begin{align}\n    H\\left(e^{j \\omega}\\right) = \\sum_{n = -\\infty}^{\\infty} h[n] e^{-j \\omega n}\n\\end{align}   Given a difference equation,   \\begin{align}\n    \\sum_{i=0}^{M} b_i x[n - i] = \\sum_{j=0}^{N} a_j y[n-j]\n\\end{align}   the frequency response is,   \\begin{align}\n    H\\left(e^{j \\omega}\\right) = \\frac{\\sum_{i=0}^{M} b_i e^{-j \\omega i}}{\\sum_{k=0}^{N} a_k e^{-j \\omega k}}\n\\end{align}", 
            "title": "Eigenfunctions - Continued"
        }, 
        {
            "location": "/2016-01-29/#examples", 
            "text": "Is $3^n$ an eigenfunction?  Yes. Since $3^n = \\left(3e^{j0}\\right)^n$.  Is $\\cos{\\omega_0 n}$ an eigenfunction?  No.", 
            "title": "Examples"
        }, 
        {
            "location": "/2016-01-29/#sinusoidal-system-responses", 
            "text": "Suppose, $x[n] = A \\cos{\\omega_0 n + \\varphi}$, then   \\begin{align}\n    x[n] &= A \\cos{\\omega_0 n + \\varphi} \\\\\\\\\n    &= \\frac{A}{2}\\left( e^{j(\\omega_0 n + \\varphi)} + e^{-j(\\omega_0 n + \\varphi)} \\right) \\\\\\\\\n    &= \\frac{A}{2}\\left( e^{j\\omega_0 n}e^{j\\varphi} + e^{-j\\omega_0 n}e^{j\\varphi} \\right) \\\\\\\\\n    &= \\frac{A}{2} e^{j\\omega_0 n}e^{j\\varphi} + \\frac{A}{2} e^{j\\omega_0 n}e^{-j\\varphi} \\\\\\\\\n    &\\xrightarrow{S} \\frac{A}{2} e^{j\\varphi} H\\left(e^{j \\omega_0}\\right) e^{j\\omega_0 n} + \\frac{A}{2} e^{-j\\varphi} H\\left(e^{-j \\omega_0}\\right) e^{j\\omega_0 n}  \\\\\\\\\n\\end{align}   This gives us,   \\begin{align}\n    y[n] &= \\frac{A}{2} e^{j\\varphi} H\\left(e^{j \\omega_0}\\right) e^{j\\omega_0 n} + \\frac{A}{2} e^{-j\\varphi} H\\left(e^{-j \\omega_0}\\right) e^{j\\omega_0 n} \\\\\\\\\n    &= A \\left|H\\left( e^{j \\omega_0} \\right)\\right|\\cos{\\left(\\omega_0 n + \\varphi - \\theta_0\\right)}\n\\end{align}", 
            "title": "Sinusoidal System Responses"
        }, 
        {
            "location": "/2016-02-03/", 
            "text": "Lecture 13 - Notes\n\n\nFebruary 3, 2016\n  \n\n\nThe Discrete-Time Fourier Transform\n\n\ndefinition\n: We define the \nDiscrete-Time Fourier Transform\n as,\n\n\n\n\n\n    X\\left( e^{j\\omega} \\right) = \\sum_{k = -\\infty}^{\\infty} x[k]e^{-j \\omega k}\n\n\n\n\n\nand the inverse transform,\n\n\n\n\n\\begin{align}\n    x[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} X\\left(e^{j\\omega}\\right) e^{j \\omega n} ~d\\omega\n\\end{align}\n\n\n\n\nExample\n\n\nFind the Fourier transform of,\n\n\n\n\n\\begin{align}\n    x[n] = a^n u[n]\n\\end{align}\n\n\n\n\nwhere $|a| \\lt 1$.\n\n\nSo,\n\n\n\n\n\\begin{align}\n    X\\left( e^{j\\omega} \\right) &= \\sum_{k = -\\infty}^{\\infty} x[k]e^{-j \\omega k} \\\\\\\\ \n    &= \\sum_{k = -\\infty}^{\\infty} a^k u[k] e^{-j \\omega k} \\\\\\\\\n    &= \\sum_{k = 0}^{\\infty} a^k e^{-j \\omega k} \\\\\\\\\n    &= \\sum_{k = 0}^{\\infty} \\left( a e^{-j \\omega} \\right)^k \\\\\\\\\n    &= \\frac{1}{1 - a e^{-j \\omega}} \\\\\\\\\n\\end{align}\n\n\n\n\nExample\n\n\nFind the inverse Fourier transform of,\n\n\n\n\n\\begin{align}\n    X\\left(e^{j\\omega}\\right) = 1 + 3e^{-j\\omega} + 2e^{-j2\\omega} - 4e^{-j3\\omega} + e^{-j10\\omega}\n\\end{align}\n\n\n\n\nUsing the properties of Fourier transforms,\n\n\n\n\n\\begin{align}\n    x[n] = \\underbrace{\\delta[n]}_{1} + \n           \\underbrace{3\\delta[n-1]}_{3e^{-j \\omega}} + \n           \\underbrace{2\\delta[n-2]}_{2e^{-j2\\omega}} - \n           \\underbrace{4\\delta[n-3]}_{4e^{-j3\\omega}} + \n           \\underbrace{\\delta[n-10]}_{e^{-j10\\omega}}\n\\end{align}", 
            "title": "2016 02 03"
        }, 
        {
            "location": "/2016-02-03/#lecture-13-notes", 
            "text": "February 3, 2016", 
            "title": "Lecture 13 - Notes"
        }, 
        {
            "location": "/2016-02-03/#the-discrete-time-fourier-transform", 
            "text": "definition : We define the  Discrete-Time Fourier Transform  as,   \n    X\\left( e^{j\\omega} \\right) = \\sum_{k = -\\infty}^{\\infty} x[k]e^{-j \\omega k}   and the inverse transform,   \\begin{align}\n    x[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} X\\left(e^{j\\omega}\\right) e^{j \\omega n} ~d\\omega\n\\end{align}", 
            "title": "The Discrete-Time Fourier Transform"
        }, 
        {
            "location": "/2016-02-03/#example", 
            "text": "Find the Fourier transform of,   \\begin{align}\n    x[n] = a^n u[n]\n\\end{align}   where $|a| \\lt 1$.  So,   \\begin{align}\n    X\\left( e^{j\\omega} \\right) &= \\sum_{k = -\\infty}^{\\infty} x[k]e^{-j \\omega k} \\\\\\\\ \n    &= \\sum_{k = -\\infty}^{\\infty} a^k u[k] e^{-j \\omega k} \\\\\\\\\n    &= \\sum_{k = 0}^{\\infty} a^k e^{-j \\omega k} \\\\\\\\\n    &= \\sum_{k = 0}^{\\infty} \\left( a e^{-j \\omega} \\right)^k \\\\\\\\\n    &= \\frac{1}{1 - a e^{-j \\omega}} \\\\\\\\\n\\end{align}", 
            "title": "Example"
        }, 
        {
            "location": "/2016-02-03/#example_1", 
            "text": "Find the inverse Fourier transform of,   \\begin{align}\n    X\\left(e^{j\\omega}\\right) = 1 + 3e^{-j\\omega} + 2e^{-j2\\omega} - 4e^{-j3\\omega} + e^{-j10\\omega}\n\\end{align}   Using the properties of Fourier transforms,   \\begin{align}\n    x[n] = \\underbrace{\\delta[n]}_{1} + \n           \\underbrace{3\\delta[n-1]}_{3e^{-j \\omega}} + \n           \\underbrace{2\\delta[n-2]}_{2e^{-j2\\omega}} - \n           \\underbrace{4\\delta[n-3]}_{4e^{-j3\\omega}} + \n           \\underbrace{\\delta[n-10]}_{e^{-j10\\omega}}\n\\end{align}", 
            "title": "Example"
        }, 
        {
            "location": "/2016-02-17/", 
            "text": "Lecture 15 - Notes\n\n\nFebruary 17, 2016\n  \n\n\nProperties of Fourier Transforms\n\n\nSymmetry\n\n\nFor an arbitrary $x[n]$,\n\n\n\n\n\\begin{align}\n    x[n] = \\underbrace{x_\\text{even}[n]}_{X_R\\left(e^{j\\omega}\\right)} + \\underbrace{x_\\text{odd}[n]}_{X_I\\left(e^{j\\omega}\\right)}\n\\end{align}\n\n\n\n\nIf,\n\n\n\n\n\\begin{gather}\n    \\left| X\\left(e^{j\\omega}\\right) \\right| = \\left| X\\left(e^{-j\\omega}\\right) \\right| \\\\\n\\end{gather}\n\n\n\n\nthen $x[n]$ is even. If,\n\n\n\n\n\\begin{align}\n    \\angle X\\left(e^{j\\omega}\\right) = \\angle X\\left(e^{-j\\omega}\\right)\n\\end{align}\n\n\n\n\nthen $x[n]$ is odd.\n\n\nTime and Frequency Shifting\n\n\nTo shift in the time domain,\n\n\n\n\n\\begin{align}\n    x[n - n_d] \\overset F \\longleftrightarrow e^{-jwn_d} X \\left( e^{j\\omega} \\right)\n\\end{align}\n\n\n\n\nTo shift in the frequency domain,\n\n\nFrequency Differentiation\n\n\nTo differentiate in the frequency domain,\n\n\n\n\n\\begin{align}\n    nx[n] \\overset F \\longleftrightarrow j \\frac{d X \\left( e^{j\\omega} \\right)}{d\\omega}\n\\end{align}\n\n\n\n\nExample\n\n\nFind $X \\left( e^{j\\omega} \\right)$ of,\n\n\n\n\n\\begin{align}\n    x[n] = (n - 1)\\left( \\frac{1}{3} \\right)^{\\left| n \\right|}\n\\end{align}\n\n\n\n\nSolution\n\n\nLet,\n\n\n\n\n\\begin{align}\n    x_1[n] &= \\left( \\frac{1}{3} \\right)^{\\left| n \\right|} \\\\\\\\\n    &= \\begin{cases} \n      \\left( \\frac{1}{3} \\right)^{ n} & n \\ge 0 \\\\\\\\\n      \\left( \\frac{1}{3} \\right)^{-n} & n \\lt 0 \\\\\\\\\n   \\end{cases}\n\\end{align}\n\n\n\n\nso,\n\n\n\n\n\\begin{align}\n    X_1 \\left( e^{j\\omega} \\right) &= \\sum_{n = -\\infty}^{\\infty} \\left( \\frac{1}{3} \\right)^{|n|} e^{-j\\omega n} \\\\\\\\\n    &= \\sum_{n = -\\infty}^{0} \\left( \\frac{1}{3} \\right)^{-n} e^{-j\\omega n} + \\sum_{n = 0}^{\\infty} \\left( \\frac{1}{3} \\right)^{n} e^{-j\\omega n} - 1 \\\\\\\\\n    &= \\sum_{p = 0}^{\\infty} \\left( \\frac{1}{3} \\right)^{p} e^{j\\omega p} + \\sum_{n = 0}^{\\infty} \\left( \\frac{1}{3} \\right)^{n} e^{-j\\omega n} - 1 \\\\\\\\\n    &= \\frac{1}{1 - \\frac{1}{3} e^{j\\omega}} + \\frac{1}{1 - \\frac{1}{3} e^{-j\\omega}} - 1 \\\\\\\\\n    &= \\frac{4}{5 - 3 \\cos{\\omega}}\n\\end{align}\n\n\n\n\nnow,\n\n\n\n\n\\begin{align}\n    x[n] &= n x_1[n] - x_1[n] \\\\\\\\\n    X \\left( e^{j\\omega} \\right) &= j \\frac{d X_1 \\left( e^{j\\omega} \\right)}{d\\omega} - X_1 \\left( e^{j\\omega} \\right) \\\\\\\\\n    &~~\\vdots \\\\\\\\\n    &= \\frac{4}{5 - 3 \\cos{\\omega}} - j \\frac{12 \\sin{\\omega}}{\\left(5 - 3 \\cos{\\omega} \\right)^2}\n\\end{align}\n\n\n\n\nConvolution\n\n\nTo transform convolution in the time domain into the frequency domain,\n\n\n\n\n\\begin{align}\n    x_1[n] &\\overset F \\longleftrightarrow X_1 \\left( e^{j\\omega} \\right) \\\\\\\\\n    x_2[n] &\\overset F \\longleftrightarrow X_2 \\left( e^{j\\omega} \\right) \\\\\\\\\n    &~~\\downarrow \\\\\\\\\n    x_1[n] * x_2[n] &\\overset F \\longleftrightarrow X_1 \\left( e^{j\\omega} \\right)X_2 \\left( e^{j\\omega} \\right) \\\\\\\\\n\\end{align}", 
            "title": "2016 02 17"
        }, 
        {
            "location": "/2016-02-17/#lecture-15-notes", 
            "text": "February 17, 2016", 
            "title": "Lecture 15 - Notes"
        }, 
        {
            "location": "/2016-02-17/#properties-of-fourier-transforms", 
            "text": "", 
            "title": "Properties of Fourier Transforms"
        }, 
        {
            "location": "/2016-02-17/#symmetry", 
            "text": "For an arbitrary $x[n]$,   \\begin{align}\n    x[n] = \\underbrace{x_\\text{even}[n]}_{X_R\\left(e^{j\\omega}\\right)} + \\underbrace{x_\\text{odd}[n]}_{X_I\\left(e^{j\\omega}\\right)}\n\\end{align}   If,   \\begin{gather}\n    \\left| X\\left(e^{j\\omega}\\right) \\right| = \\left| X\\left(e^{-j\\omega}\\right) \\right| \\\\\n\\end{gather}   then $x[n]$ is even. If,   \\begin{align}\n    \\angle X\\left(e^{j\\omega}\\right) = \\angle X\\left(e^{-j\\omega}\\right)\n\\end{align}   then $x[n]$ is odd.", 
            "title": "Symmetry"
        }, 
        {
            "location": "/2016-02-17/#time-and-frequency-shifting", 
            "text": "To shift in the time domain,   \\begin{align}\n    x[n - n_d] \\overset F \\longleftrightarrow e^{-jwn_d} X \\left( e^{j\\omega} \\right)\n\\end{align}   To shift in the frequency domain,", 
            "title": "Time and Frequency Shifting"
        }, 
        {
            "location": "/2016-02-17/#frequency-differentiation", 
            "text": "To differentiate in the frequency domain,   \\begin{align}\n    nx[n] \\overset F \\longleftrightarrow j \\frac{d X \\left( e^{j\\omega} \\right)}{d\\omega}\n\\end{align}", 
            "title": "Frequency Differentiation"
        }, 
        {
            "location": "/2016-02-17/#example", 
            "text": "Find $X \\left( e^{j\\omega} \\right)$ of,   \\begin{align}\n    x[n] = (n - 1)\\left( \\frac{1}{3} \\right)^{\\left| n \\right|}\n\\end{align}", 
            "title": "Example"
        }, 
        {
            "location": "/2016-02-17/#solution", 
            "text": "Let,   \\begin{align}\n    x_1[n] &= \\left( \\frac{1}{3} \\right)^{\\left| n \\right|} \\\\\\\\\n    &= \\begin{cases} \n      \\left( \\frac{1}{3} \\right)^{ n} & n \\ge 0 \\\\\\\\\n      \\left( \\frac{1}{3} \\right)^{-n} & n \\lt 0 \\\\\\\\\n   \\end{cases}\n\\end{align}   so,   \\begin{align}\n    X_1 \\left( e^{j\\omega} \\right) &= \\sum_{n = -\\infty}^{\\infty} \\left( \\frac{1}{3} \\right)^{|n|} e^{-j\\omega n} \\\\\\\\\n    &= \\sum_{n = -\\infty}^{0} \\left( \\frac{1}{3} \\right)^{-n} e^{-j\\omega n} + \\sum_{n = 0}^{\\infty} \\left( \\frac{1}{3} \\right)^{n} e^{-j\\omega n} - 1 \\\\\\\\\n    &= \\sum_{p = 0}^{\\infty} \\left( \\frac{1}{3} \\right)^{p} e^{j\\omega p} + \\sum_{n = 0}^{\\infty} \\left( \\frac{1}{3} \\right)^{n} e^{-j\\omega n} - 1 \\\\\\\\\n    &= \\frac{1}{1 - \\frac{1}{3} e^{j\\omega}} + \\frac{1}{1 - \\frac{1}{3} e^{-j\\omega}} - 1 \\\\\\\\\n    &= \\frac{4}{5 - 3 \\cos{\\omega}}\n\\end{align}   now,   \\begin{align}\n    x[n] &= n x_1[n] - x_1[n] \\\\\\\\\n    X \\left( e^{j\\omega} \\right) &= j \\frac{d X_1 \\left( e^{j\\omega} \\right)}{d\\omega} - X_1 \\left( e^{j\\omega} \\right) \\\\\\\\\n    &~~\\vdots \\\\\\\\\n    &= \\frac{4}{5 - 3 \\cos{\\omega}} - j \\frac{12 \\sin{\\omega}}{\\left(5 - 3 \\cos{\\omega} \\right)^2}\n\\end{align}", 
            "title": "Solution"
        }, 
        {
            "location": "/2016-02-17/#convolution", 
            "text": "To transform convolution in the time domain into the frequency domain,   \\begin{align}\n    x_1[n] &\\overset F \\longleftrightarrow X_1 \\left( e^{j\\omega} \\right) \\\\\\\\\n    x_2[n] &\\overset F \\longleftrightarrow X_2 \\left( e^{j\\omega} \\right) \\\\\\\\\n    &~~\\downarrow \\\\\\\\\n    x_1[n] * x_2[n] &\\overset F \\longleftrightarrow X_1 \\left( e^{j\\omega} \\right)X_2 \\left( e^{j\\omega} \\right) \\\\\\\\\n\\end{align}", 
            "title": "Convolution"
        }, 
        {
            "location": "/2016-02-19/", 
            "text": "Lecture 16 - Notes\n\n\nFebruary 19, 2016\n  \n\n\nI should take better notes.", 
            "title": "2016 02 19"
        }, 
        {
            "location": "/2016-02-19/#lecture-16-notes", 
            "text": "February 19, 2016     I should take better notes.", 
            "title": "Lecture 16 - Notes"
        }, 
        {
            "location": "/2016-02-24/", 
            "text": "Lecture 18 - Notes\n\n\nFebruary 24, 2016\n  \n\n\nRegion of Convergence\n\n\ndefintion\n: The \nregion of convergence\n, $\\mathcal S \\subset \\mathbb C$ of the Z-transform of $x[n]$ is,\n\n\n\n\n\\begin{aligned}\n    \\mathcal S = \\left\\{ z \\in \\mathbb C: \\sum_{n = -\\infty}^{\\infty} \\left| x[n] z^{-n}\\right| \\lt \\infty \\right\\}\n\\end{aligned}\n\n\n\n\nExample\n\n\nCompute the Z-Transform for $x[n] = a^n u[n]$\n\n\nConsider,\n\n\n\n\n\\begin{aligned}\n    x[n] &= a^n u[n] \\\\\\\\\n    X(z) &= \\sum_{n = -\\infty}^{\\infty} a^n u[n] z^{-n} \\\\\\\\\n    &= \\sum_{n = 0}^{\\infty} a^n z^{-n} \\\\\\\\\n    &= \\sum_{n = 0}^{\\infty} \\left( a z^{-1} \\right)^n \\\\\\\\\n    &= \\frac{1}{1 - a z^{-1}} \\\\\\\\\n    &= \\frac{z}{z - a}\n\\end{aligned}\n\n\n\n\nif $\\left| az^{-1} \\right| \\lt 1$.\n\n\nAbsolute Summability\n\n\n$x[n]$ is \nabsolutely summable\n if and only if,\n\n\n\n\n\\begin{aligned}\n    \\sum_{n = -\\infty}^{\\infty} \\left| x[n] \\right| \\lt \\infty\n\\end{aligned}", 
            "title": "2016 02 24"
        }, 
        {
            "location": "/2016-02-24/#lecture-18-notes", 
            "text": "February 24, 2016", 
            "title": "Lecture 18 - Notes"
        }, 
        {
            "location": "/2016-02-24/#region-of-convergence", 
            "text": "defintion : The  region of convergence , $\\mathcal S \\subset \\mathbb C$ of the Z-transform of $x[n]$ is,   \\begin{aligned}\n    \\mathcal S = \\left\\{ z \\in \\mathbb C: \\sum_{n = -\\infty}^{\\infty} \\left| x[n] z^{-n}\\right| \\lt \\infty \\right\\}\n\\end{aligned}", 
            "title": "Region of Convergence"
        }, 
        {
            "location": "/2016-02-24/#example", 
            "text": "Compute the Z-Transform for $x[n] = a^n u[n]$  Consider,   \\begin{aligned}\n    x[n] &= a^n u[n] \\\\\\\\\n    X(z) &= \\sum_{n = -\\infty}^{\\infty} a^n u[n] z^{-n} \\\\\\\\\n    &= \\sum_{n = 0}^{\\infty} a^n z^{-n} \\\\\\\\\n    &= \\sum_{n = 0}^{\\infty} \\left( a z^{-1} \\right)^n \\\\\\\\\n    &= \\frac{1}{1 - a z^{-1}} \\\\\\\\\n    &= \\frac{z}{z - a}\n\\end{aligned}   if $\\left| az^{-1} \\right| \\lt 1$.", 
            "title": "Example"
        }, 
        {
            "location": "/2016-02-24/#absolute-summability", 
            "text": "$x[n]$ is  absolutely summable  if and only if,   \\begin{aligned}\n    \\sum_{n = -\\infty}^{\\infty} \\left| x[n] \\right| \\lt \\infty\n\\end{aligned}", 
            "title": "Absolute Summability"
        }, 
        {
            "location": "/2016-02-26/", 
            "text": "Lecture 19 - Notes\n\n\nFebruary 26, 2016\n  \n\n\nRegion of Convergence Continued\n\n\nProperties\n\n\n\n\nThe Region of Convergence consist of a ring centered around the origin.\n\n\nThe Discrete-Time Fourier Transform of $x[n]$ is convergent if and only if the Region of Convergence of the Z-Transform of $x[n]$ contains the unit circle.\n\n\nThe Region of Convergence does not contain any poles.\n\n\nIf $x[n]$ is of finite duration, then the Region of Convergence is the entire z-plane, except possibly $z = 0$ or $z = \\infty$.\n\n\nIf $x[n]$ is a \nright-sided\n sequence the Region of Convergence extends outward from the outermost finite pole (possibly to $z = \\infty$).\n\n\nIf $x[n]$ is a \nleft-sided\n sequence the Region of Convergence extends inward from the innermost finite pole (possibly including $z=0$).\n\n\nIf $x[n]$ is a \ntwo-sided\n sequence then the Region of Convergence is a ring bounded by interior and exterior poles.\n\n\nThe Region of convergence must be a connect region.\n\n\nIf $x[n]$ and $y[n]$ have Regions of Convergence, $R_x$ and $R_y$, then a linear combination, $v[n] = ax[n] + by[n]$, will have the Region of Convergence that include the Regions of Convergence of $x[n]$ and $y[n]$, $R_v \\supseteq R_x \\cap R_y$.\n\n\n\n\nThese properties will be provided on the midterm.\n\n\nExample\n\n\nFind the region of convergence of\n\n\n\n\n\\begin{aligned}\n    X(z) = \\frac{1}{\n    \\left( 1 - \\frac{1}{3}z^{-1} \\right)\n    \\left( 1 - 2z^{-1} \\right)\n    }\n\\end{aligned}", 
            "title": "2016 02 26"
        }, 
        {
            "location": "/2016-02-26/#lecture-19-notes", 
            "text": "February 26, 2016", 
            "title": "Lecture 19 - Notes"
        }, 
        {
            "location": "/2016-02-26/#region-of-convergence-continued", 
            "text": "", 
            "title": "Region of Convergence Continued"
        }, 
        {
            "location": "/2016-02-26/#properties", 
            "text": "The Region of Convergence consist of a ring centered around the origin.  The Discrete-Time Fourier Transform of $x[n]$ is convergent if and only if the Region of Convergence of the Z-Transform of $x[n]$ contains the unit circle.  The Region of Convergence does not contain any poles.  If $x[n]$ is of finite duration, then the Region of Convergence is the entire z-plane, except possibly $z = 0$ or $z = \\infty$.  If $x[n]$ is a  right-sided  sequence the Region of Convergence extends outward from the outermost finite pole (possibly to $z = \\infty$).  If $x[n]$ is a  left-sided  sequence the Region of Convergence extends inward from the innermost finite pole (possibly including $z=0$).  If $x[n]$ is a  two-sided  sequence then the Region of Convergence is a ring bounded by interior and exterior poles.  The Region of convergence must be a connect region.  If $x[n]$ and $y[n]$ have Regions of Convergence, $R_x$ and $R_y$, then a linear combination, $v[n] = ax[n] + by[n]$, will have the Region of Convergence that include the Regions of Convergence of $x[n]$ and $y[n]$, $R_v \\supseteq R_x \\cap R_y$.   These properties will be provided on the midterm.", 
            "title": "Properties"
        }, 
        {
            "location": "/2016-02-26/#example", 
            "text": "Find the region of convergence of   \\begin{aligned}\n    X(z) = \\frac{1}{\n    \\left( 1 - \\frac{1}{3}z^{-1} \\right)\n    \\left( 1 - 2z^{-1} \\right)\n    }\n\\end{aligned}", 
            "title": "Example"
        }, 
        {
            "location": "/2016-03-01/", 
            "text": "Lecture 20 - Notes\n\n\nMarch 1, 2016\n  \n\n\nThe Inverse Z-Transform\n\n\nIf we express the Z-transform as a Fourier Transform of an equally weighted sequence,\n\n\n\n\n\\begin{aligned}\n    x[n] = \\frac{1}{2 \\pi j} \\oint X(z) z^{n-1} ~dz\n\\end{aligned}\n\n\n\n\nFor rational Z-transforms we can compute the inverse Z-transforms alternate ways,\n\n\n\n\nInspection\n\n\nPartial Fraction Expansion\n\n\nPower Series Expansion\n\n\n\n\nInspection\n\n\nUse a table of Z-transform properties and pairs to convert back to the time domain.\n\n\ne.g.\n\n\nDetermine $h[n]$ given,\n\n\n\n\n\\begin{aligned}\n    H(z) = \\frac{1 - z^{-1}}{1 + \\frac{3}{4} z^{-1}}\n\\end{aligned}\n\n\n\n\nConsider,\n\n\n\n\n\\begin{aligned}\n    H(z) &= \\frac{1 - z^{-1}}{1 + \\frac{3}{4} z^{-1}} \\\\\\\\\n    &= \\underbrace{\\frac{1}{1 + \\frac{3}{4} z^{-1}}}_\\text{exponential} - \\underbrace{\\frac{z^{-1}}{1 + \\frac{3}{4} z^{-1}}}_\\text{shifted exponential} \\\\\\\\\n    &\\downarrow\\\\\\\\\n    h[n] &= \\left( \\frac{3}{4} \\right)^n u[n] - \\left( \\frac{3}{4} \\right)^{n-1} u[n-1]\n\\end{aligned}\n\n\n\n\nPartial Fraction Expansion\n\n\nExpand two sums which are partial fractions,\n\n\n\n\n\\begin{aligned}\n    X(z) &= \\frac{\\sum_{k=0}^M b_k z^{-k}}{\\sum_{k=0}^N a_k z^{-k}} \\\\\\\\\n    &\\downarrow \\\\\\\\\n    X(z) &= \\sum_{k=1}^N \\frac{A_k}{1-d_k z^-1}\n\\end{aligned}\n\n\n\n\ne.g.\n\n\nDetermine the inverse Z-transform of,\n\n\n\n\n\\begin{aligned}\n    X(z) &= \\frac{3z^2 - \\frac{5}{6}z}{\\left(z - \\frac{1}{4}\\right)\\left(z - \\frac{1}{3}\\right)}\n\\end{aligned}\n\n\n\n\nwhere $\\left| z \\right| \\lt \\frac{1}{3}$.\n\n\nWe identify $M = 1$ and $N = 2$ and perform the partial fraction expansion,\n\n\n\n\n\\begin{aligned}\n    \\frac{3z - \\frac{5}{6}z}{\\left(z - \\frac{1}{4}\\right)\\left(z - \\frac{1}{3}\\right)} &= \\frac{A}{\\left(z - \\frac{1}{4}\\right)} + \\frac{B}{\\left(z - \\frac{1}{3}\\right)} \\\\\\\\\n    3z^2 - \\frac{5}{6}z  &= A \\left(z - \\frac{1}{3}\\right) + B \\left(z - \\frac{1}{4}\\right) \\\\\\\\\n\\end{aligned}\n\n\n\n\nTODO\n\n\nPower Series Expansion\n\n\n\n\n\\begin{aligned}\n    X(z) &= \\frac{\\sum_{k=0}^M b_k z^{-k}}{\\sum_{k=0}^N a_k z^{-k}} \\\\\\\\\n    &\\downarrow \\\\\\\\\n    X(z) &= \\sum_{n=-\\infty}^{+\\infty} x[n]z^{-1}\n\\end{aligned}\n\n\n\n\ne.g.\n\n\nDetermine the inverse Z-transform of,\n\n\n\n\n\\begin{aligned}\n    X(z) &= (1 + 2z)(1 + 3z^{-1})\n\\end{aligned}\n\n\n\n\nStart by expanding,\n\n\n\n\n\\begin{aligned}\n    X(z) &= (1 + 2z)(1 + 3z^{-1}) \\\\\\\\\n    &= 1 - 2z + 3z^{-1} + 6 \\\\\\\\\n    &= 3z^{-1} + 7 - 2z \\\\\\\n    &\\downarrow \\\\\\\\\n    x[n] &= \\begin{cases} \n      3 & n =  1 \\\\\\\\\n      7 & n =  0 \\\\\\\\\n      2 & n = -1 \\\\\\\\\n   \\end{cases}\n\\end{aligned}\n\n\n\n\ne.g.\n\n\nDetermine the inverse Z-transform of,\n\n\n\n\n\\begin{aligned}\n    X(z) &= \\frac{1}{1 + \\frac{1}{2}z^{-1}}\n\\end{aligned}\n\n\n\n\nTODO", 
            "title": "2016 03 01"
        }, 
        {
            "location": "/2016-03-01/#lecture-20-notes", 
            "text": "March 1, 2016", 
            "title": "Lecture 20 - Notes"
        }, 
        {
            "location": "/2016-03-01/#the-inverse-z-transform", 
            "text": "If we express the Z-transform as a Fourier Transform of an equally weighted sequence,   \\begin{aligned}\n    x[n] = \\frac{1}{2 \\pi j} \\oint X(z) z^{n-1} ~dz\n\\end{aligned}   For rational Z-transforms we can compute the inverse Z-transforms alternate ways,   Inspection  Partial Fraction Expansion  Power Series Expansion", 
            "title": "The Inverse Z-Transform"
        }, 
        {
            "location": "/2016-03-01/#inspection", 
            "text": "Use a table of Z-transform properties and pairs to convert back to the time domain.  e.g.  Determine $h[n]$ given,   \\begin{aligned}\n    H(z) = \\frac{1 - z^{-1}}{1 + \\frac{3}{4} z^{-1}}\n\\end{aligned}   Consider,   \\begin{aligned}\n    H(z) &= \\frac{1 - z^{-1}}{1 + \\frac{3}{4} z^{-1}} \\\\\\\\\n    &= \\underbrace{\\frac{1}{1 + \\frac{3}{4} z^{-1}}}_\\text{exponential} - \\underbrace{\\frac{z^{-1}}{1 + \\frac{3}{4} z^{-1}}}_\\text{shifted exponential} \\\\\\\\\n    &\\downarrow\\\\\\\\\n    h[n] &= \\left( \\frac{3}{4} \\right)^n u[n] - \\left( \\frac{3}{4} \\right)^{n-1} u[n-1]\n\\end{aligned}", 
            "title": "Inspection"
        }, 
        {
            "location": "/2016-03-01/#partial-fraction-expansion", 
            "text": "Expand two sums which are partial fractions,   \\begin{aligned}\n    X(z) &= \\frac{\\sum_{k=0}^M b_k z^{-k}}{\\sum_{k=0}^N a_k z^{-k}} \\\\\\\\\n    &\\downarrow \\\\\\\\\n    X(z) &= \\sum_{k=1}^N \\frac{A_k}{1-d_k z^-1}\n\\end{aligned}   e.g.  Determine the inverse Z-transform of,   \\begin{aligned}\n    X(z) &= \\frac{3z^2 - \\frac{5}{6}z}{\\left(z - \\frac{1}{4}\\right)\\left(z - \\frac{1}{3}\\right)}\n\\end{aligned}   where $\\left| z \\right| \\lt \\frac{1}{3}$.  We identify $M = 1$ and $N = 2$ and perform the partial fraction expansion,   \\begin{aligned}\n    \\frac{3z - \\frac{5}{6}z}{\\left(z - \\frac{1}{4}\\right)\\left(z - \\frac{1}{3}\\right)} &= \\frac{A}{\\left(z - \\frac{1}{4}\\right)} + \\frac{B}{\\left(z - \\frac{1}{3}\\right)} \\\\\\\\\n    3z^2 - \\frac{5}{6}z  &= A \\left(z - \\frac{1}{3}\\right) + B \\left(z - \\frac{1}{4}\\right) \\\\\\\\\n\\end{aligned}   TODO", 
            "title": "Partial Fraction Expansion"
        }, 
        {
            "location": "/2016-03-01/#power-series-expansion", 
            "text": "\\begin{aligned}\n    X(z) &= \\frac{\\sum_{k=0}^M b_k z^{-k}}{\\sum_{k=0}^N a_k z^{-k}} \\\\\\\\\n    &\\downarrow \\\\\\\\\n    X(z) &= \\sum_{n=-\\infty}^{+\\infty} x[n]z^{-1}\n\\end{aligned}   e.g.  Determine the inverse Z-transform of,   \\begin{aligned}\n    X(z) &= (1 + 2z)(1 + 3z^{-1})\n\\end{aligned}   Start by expanding,   \\begin{aligned}\n    X(z) &= (1 + 2z)(1 + 3z^{-1}) \\\\\\\\\n    &= 1 - 2z + 3z^{-1} + 6 \\\\\\\\\n    &= 3z^{-1} + 7 - 2z \\\\\\\n    &\\downarrow \\\\\\\\\n    x[n] &= \\begin{cases} \n      3 & n =  1 \\\\\\\\\n      7 & n =  0 \\\\\\\\\n      2 & n = -1 \\\\\\\\\n   \\end{cases}\n\\end{aligned}   e.g.  Determine the inverse Z-transform of,   \\begin{aligned}\n    X(z) &= \\frac{1}{1 + \\frac{1}{2}z^{-1}}\n\\end{aligned}   TODO", 
            "title": "Power Series Expansion"
        }
    ]
}